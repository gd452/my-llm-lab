"""
ğŸ“‰ Loss Functions: ì†ì‹¤ í•¨ìˆ˜

ì´ íŒŒì¼ì—ì„œ êµ¬í˜„í•  ê²ƒ:
1. MSE (Mean Squared Error) - íšŒê·€ ë¬¸ì œìš©
2. Binary Cross-Entropy - ì´ì§„ ë¶„ë¥˜ìš© (ì„ íƒ)

ì†ì‹¤ í•¨ìˆ˜ëŠ” ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
í•™ìŠµì˜ ëª©í‘œëŠ” ì´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
"""

if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ path ì¶”ê°€
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import math


def mse_loss(predictions, targets):
    """
    Mean Squared Error Loss
    
    MSE = (1/n) * Î£(pred_i - target_i)Â²
    
    Args:
        predictions: ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸ (Value ê°ì²´ë“¤)
        targets: ëª©í‘œê°’ ë¦¬ìŠ¤íŠ¸ (Value ê°ì²´ë“¤ ë˜ëŠ” ìˆ«ìë“¤)
    
    Returns:
        í‰ê·  ì œê³± ì˜¤ì°¨ (Value ê°ì²´)
        
    TODO:
    1. predictionsì™€ targetsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    2. ê° ì˜ˆì¸¡ê°’ê³¼ ëª©í‘œê°’ì˜ ì°¨ì´ë¥¼ ì œê³±
    3. í‰ê·  ê³„ì‚°
    """
    
    # ë‹¨ì¼ ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if not isinstance(predictions, list):
        predictions = [predictions]
    if not isinstance(targets, list):
        targets = [targets]
        
    # MSE ê³„ì‚°
    losses = [(pred - target)**2 for pred, target in zip(predictions, targets)]
    return sum(losses) * (1.0 / len(losses))


def binary_cross_entropy(predictions, targets, epsilon=1e-7):
    """
    Binary Cross-Entropy Loss (ì„ íƒ êµ¬í˜„)
    
    BCE = -Î£(target * log(pred) + (1-target) * log(1-pred))
    
    Args:
        predictions: ì˜ˆì¸¡ í™•ë¥  (0~1 ì‚¬ì´, sigmoid ì¶œë ¥)
        targets: ì‹¤ì œ ë ˆì´ë¸” (0 ë˜ëŠ” 1)
        epsilon: ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•œ ì‘ì€ ê°’
    
    Returns:
        í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤
        
    Note:
        ì´ í•¨ìˆ˜ëŠ” ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤.
        log í•¨ìˆ˜ê°€ Value í´ë˜ìŠ¤ì— êµ¬í˜„ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    # ì„ íƒ êµ¬í˜„
    if not isinstance(predictions, list):
        predictions = [predictions]
    if not isinstance(targets, list):
        targets = [targets]
        
    losses = [-target * math.log(pred + epsilon) - (1 - target) * math.log(1 - pred + epsilon) for pred, target in zip(predictions, targets)]
    return sum(losses) * (1.0 / len(losses))


def accuracy(predictions, targets, threshold=0.5):
    """
    ì •í™•ë„ ê³„ì‚° (ë¶„ë¥˜ ë¬¸ì œìš©)
    
    Args:
        predictions: ì˜ˆì¸¡ê°’
        targets: ì‹¤ì œê°’
        threshold: ì´ì§„ ë¶„ë¥˜ ì„ê³„ê°’
    
    Returns:
        ì •í™•ë„ (0~1 ì‚¬ì´ì˜ float)
        
    TODO:
    1. ì˜ˆì¸¡ê°’ì„ thresholdì™€ ë¹„êµí•˜ì—¬ 0/1ë¡œ ë³€í™˜
    2. ì‹¤ì œê°’ê³¼ ë¹„êµí•˜ì—¬ ë§ì€ ê°œìˆ˜ ê³„ì‚°
    3. ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨ ë°˜í™˜
    """
    return sum(1 for pred, target in zip(predictions, targets) if pred >= threshold and target == 1 or pred < threshold and target == 0) / len(predictions)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ§ª Loss Functions í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    from core.autograd import Value
    
    # MSE í…ŒìŠ¤íŠ¸
    predictions = [Value(0.5), Value(0.8)]
    targets = [Value(0.0), Value(1.0)]
    
    loss = mse_loss(predictions, targets)
    print(f"ì˜ˆì¸¡: {[p.data for p in predictions]}")
    print(f"ëª©í‘œ: {[t.data for t in targets]}")
    print(f"MSE Loss: {loss.data}")
    
    # Backward pass í…ŒìŠ¤íŠ¸
    loss.backward()
    print(f"Gradients: {[p.grad for p in predictions]}")