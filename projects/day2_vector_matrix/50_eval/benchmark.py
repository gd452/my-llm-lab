"""
ğŸ“Š Performance Benchmark: ìŠ¤ì¹¼ë¼ vs ë²¡í„° ì—°ì‚° ë¹„êµ

ìŠ¤ì¹¼ë¼ ì—°ì‚°ê³¼ ë²¡í„° ì—°ì‚°ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ì§ì ‘ í™•ì¸í•©ë‹ˆë‹¤.
"""

import numpy as np
import time
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))

from core.nn_vectorized import MLPVectorized
from core.mlp import MLP
from core.autograd import Value


def benchmark_forward_pass():
    """Forward pass ì„±ëŠ¥ ë¹„êµ"""
    print("\nğŸƒ Forward Pass ë²¤ì¹˜ë§ˆí¬")
    print("-" * 50)
    
    # ë°ì´í„° ì¤€ë¹„
    batch_size = 32
    input_dim = 100
    hidden_dims = [64, 32]
    output_dim = 10
    
    # ë²¡í„°í™”ëœ ëª¨ë¸
    vectorized_model = MLPVectorized(input_dim, hidden_dims, output_dim)
    
    # ìŠ¤ì¹¼ë¼ ëª¨ë¸
    scalar_model = MLP(input_dim, hidden_dims + [output_dim])
    
    # ì…ë ¥ ë°ì´í„°
    X_numpy = np.random.randn(batch_size, input_dim)
    
    # ë²¡í„°í™” ì—°ì‚°
    start = time.time()
    for _ in range(10):
        _ = vectorized_model.forward(X_numpy)
    vectorized_time = time.time() - start
    
    # ìŠ¤ì¹¼ë¼ ì—°ì‚°
    start = time.time()
    for _ in range(10):
        for i in range(batch_size):
            x_values = [Value(x) for x in X_numpy[i]]
            _ = scalar_model(x_values)
    scalar_time = time.time() - start
    
    print(f"ğŸ“Š ê²°ê³¼ (10íšŒ ë°˜ë³µ, batch_size={batch_size}):")
    print(f"   ë²¡í„°í™”: {vectorized_time:.4f}ì´ˆ")
    print(f"   ìŠ¤ì¹¼ë¼: {scalar_time:.4f}ì´ˆ")
    print(f"   ì†ë„ í–¥ìƒ: {scalar_time/vectorized_time:.1f}ë°° ë¹ ë¦„!")
    
    return vectorized_time, scalar_time


def benchmark_matrix_ops():
    """í–‰ë ¬ ì—°ì‚° ì„±ëŠ¥ ë¹„êµ"""
    print("\nğŸ”¢ í–‰ë ¬ ì—°ì‚° ë²¤ì¹˜ë§ˆí¬")
    print("-" * 50)
    
    sizes = [10, 50, 100, 200]
    
    print("í–‰ë ¬ í¬ê¸° | NumPy (ms) | Python Loop (ms) | ì†ë„ í–¥ìƒ")
    print("-" * 60)
    
    for size in sizes:
        A = np.random.randn(size, size)
        B = np.random.randn(size, size)
        
        # NumPy í–‰ë ¬ê³±
        start = time.time()
        for _ in range(10):
            C = A @ B
        numpy_time = (time.time() - start) * 100  # msë¡œ ë³€í™˜
        
        # Python ë£¨í”„
        start = time.time()
        for _ in range(10):
            C = [[sum(A[i][k] * B[k][j] for k in range(size))
                  for j in range(size)]
                 for i in range(size)]
        loop_time = (time.time() - start) * 100  # msë¡œ ë³€í™˜
        
        speedup = loop_time / numpy_time
        print(f"{size:4d}x{size:<4d} | {numpy_time:10.2f} | {loop_time:16.2f} | {speedup:8.1f}x")


def benchmark_activation_functions():
    """í™œì„±í™” í•¨ìˆ˜ ì„±ëŠ¥ ë¹„êµ"""
    print("\nâš¡ í™œì„±í™” í•¨ìˆ˜ ë²¤ì¹˜ë§ˆí¬")
    print("-" * 50)
    
    sizes = [1000, 10000, 100000]
    
    print("ë°°ì—´ í¬ê¸° | ë²¡í„°í™” ReLU (ms) | ìŠ¤ì¹¼ë¼ ReLU (ms) | ì†ë„ í–¥ìƒ")
    print("-" * 65)
    
    for size in sizes:
        x = np.random.randn(size)
        
        # ë²¡í„°í™” ReLU
        start = time.time()
        for _ in range(100):
            result = np.maximum(0, x)
        vector_time = (time.time() - start) * 10  # msë¡œ ë³€í™˜
        
        # ìŠ¤ì¹¼ë¼ ReLU
        start = time.time()
        for _ in range(100):
            result = [max(0, xi) for xi in x]
        scalar_time = (time.time() - start) * 10  # msë¡œ ë³€í™˜
        
        speedup = scalar_time / vector_time
        print(f"{size:8d} | {vector_time:16.2f} | {scalar_time:16.2f} | {speedup:8.1f}x")


def benchmark_batch_processing():
    """ë°°ì¹˜ í¬ê¸°ë³„ ì²˜ë¦¬ ì†ë„"""
    print("\nğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬")
    print("-" * 50)
    
    # ëª¨ë¸ ìƒì„±
    model = MLPVectorized(100, [64, 32], 10)
    
    batch_sizes = [1, 8, 32, 128, 512]
    total_samples = 1024
    
    print("Batch Size | Time (s) | Throughput (samples/s)")
    print("-" * 50)
    
    for bs in batch_sizes:
        X = np.random.randn(total_samples, 100)
        
        start = time.time()
        for i in range(0, total_samples, bs):
            batch = X[i:i+bs]
            _ = model.forward(batch)
        
        elapsed = time.time() - start
        throughput = total_samples / elapsed
        
        print(f"{bs:10d} | {elapsed:8.4f} | {throughput:20.1f}")


def benchmark_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ"""
    print("\nğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¶„ì„")
    print("-" * 50)
    
    # í° ë°°ì—´ ìƒì„±
    size = 1000000
    
    # Broadcasting vs Explicit ë³µì‚¬
    a = np.random.randn(size)
    b = np.random.randn(1)
    
    # Broadcasting (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
    start = time.time()
    result = a + b  # bê°€ ìë™ìœ¼ë¡œ broadcast
    broadcast_time = time.time() - start
    
    # Explicit ë³µì‚¬ (ë©”ëª¨ë¦¬ ë‚­ë¹„)
    start = time.time()
    b_repeated = np.tile(b, size)
    result = a + b_repeated
    explicit_time = time.time() - start
    
    print(f"ë°°ì—´ í¬ê¸°: {size:,}")
    print(f"Broadcasting: {broadcast_time:.4f}ì´ˆ")
    print(f"Explicit ë³µì‚¬: {explicit_time:.4f}ì´ˆ")
    print(f"ë©”ëª¨ë¦¬ ì ˆì•½: {explicit_time/broadcast_time:.1f}ë°° íš¨ìœ¨ì !")


def visualize_speedup():
    """ì†ë„ í–¥ìƒ ì‹œê°í™”"""
    print("\nğŸ“ˆ ì „ì²´ ì„±ëŠ¥ í–¥ìƒ ìš”ì•½")
    print("=" * 60)
    
    # ë‹¤ì–‘í•œ í¬ê¸°ì—ì„œ í…ŒìŠ¤íŠ¸
    sizes = [10, 50, 100, 200, 500]
    speedups = []
    
    for size in sizes:
        # ê°„ë‹¨í•œ ë²¡í„° ì—°ì‚°
        a = np.random.randn(size)
        b = np.random.randn(size)
        
        # NumPy
        start = time.time()
        for _ in range(1000):
            c = a + b
        numpy_time = time.time() - start
        
        # Python ë¦¬ìŠ¤íŠ¸
        a_list = a.tolist()
        b_list = b.tolist()
        start = time.time()
        for _ in range(1000):
            c = [a_list[i] + b_list[i] for i in range(size)]
        list_time = time.time() - start
        
        speedups.append(list_time / numpy_time)
    
    # í…ìŠ¤íŠ¸ ê·¸ë˜í”„
    print("\nì†ë„ í–¥ìƒ (ë°°)")
    print("    â†‘")
    
    max_speedup = max(speedups)
    height = 10
    
    for h in range(height, -1, -1):
        line = f"{max_speedup * h / height:5.0f}â”‚"
        
        for speedup in speedups:
            if speedup / max_speedup * height >= h:
                line += " â–ˆâ–ˆ"
            else:
                line += "   "
        
        print(line)
    
    print("     â””" + "â”€â”€â”€" * len(sizes) + "â†’ í¬ê¸°")
    print("      ", end="")
    for size in sizes:
        print(f"{size:3d}", end="")
    print()
    
    print(f"\ní‰ê·  ì†ë„ í–¥ìƒ: {np.mean(speedups):.1f}ë°°")


def main():
    """ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸš€ NumPy ë²¡í„°í™” vs ìŠ¤ì¹¼ë¼ ì—°ì‚° ì„±ëŠ¥ ë¹„êµ")
    print("=" * 60)
    
    # ê° ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark_matrix_ops()
    benchmark_activation_functions()
    vec_time, scalar_time = benchmark_forward_pass()
    benchmark_batch_processing()
    benchmark_memory_usage()
    visualize_speedup()
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ìµœì¢… ê²°ë¡ :")
    print("=" * 60)
    
    overall_speedup = scalar_time / vec_time
    
    print(f"""
ë²¡í„°í™”ëœ ì—°ì‚°ì€ ìŠ¤ì¹¼ë¼ ì—°ì‚°ë³´ë‹¤:
- ì „ì²´ì ìœ¼ë¡œ {overall_speedup:.1f}ë°° ë¹ ë¦„
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  (Broadcasting í™œìš©)
- ì½”ë“œê°€ ë” ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ì›€
- GPU ê°€ì† ê°€ëŠ¥ (PyTorch/TensorFlowë¡œ ì „í™˜ ì‹œ)

ğŸ’¡ êµí›ˆ: "ë£¨í”„ë¥¼ í”¼í•˜ê³  ë²¡í„°í™”í•˜ë¼!"
    """)
    
    print("ğŸ‰" * 20)
    print("ë²¡í„°í™”ì˜ í˜ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤!")
    print("ì´ì œ ë” í° ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì— ë„ì „í•˜ì„¸ìš”!")
    print("ğŸ‰" * 20)


if __name__ == "__main__":
    main()