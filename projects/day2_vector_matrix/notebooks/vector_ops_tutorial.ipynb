{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔢 Vector & Matrix Operations Tutorial\n",
    "\n",
    "이 노트북에서는 NumPy를 활용한 벡터/행렬 연산을 실습합니다.\n",
    "스칼라 연산에서 벡터 연산으로 전환하여 효율성을 극대화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 환경 설정 완료!\n",
      "NumPy 버전: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 상위 디렉토리를 path에 추가\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('.')))))\n",
    "\n",
    "# core 모듈 import\n",
    "from core.tensor_ops import (\n",
    "    matmul, relu, sigmoid, softmax,\n",
    "    mse_loss, cross_entropy, batch_norm,\n",
    "    one_hot, accuracy\n",
    ")\n",
    "from core.nn_vectorized import LinearLayer, MLPVectorized, SGDOptimizer\n",
    "\n",
    "print(\"✅ 환경 설정 완료!\")\n",
    "print(f\"NumPy 버전: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NumPy 기초: 스칼라 vs 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐌 스칼라 연산: 0.0042초\n",
      "🚀 벡터 연산: 0.0002초\n",
      "⚡ 속도 향상: 19.3배 빠름!\n"
     ]
    }
   ],
   "source": [
    "# 스칼라 연산 (느림)\n",
    "def scalar_add(a, b):\n",
    "    result = []\n",
    "    for i in range(len(a)):\n",
    "        result.append(a[i] + b[i])\n",
    "    return result\n",
    "\n",
    "# 벡터 연산 (빠름)\n",
    "def vector_add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# 성능 비교\n",
    "size = 100000\n",
    "a_list = list(range(size))\n",
    "b_list = list(range(size))\n",
    "a_array = np.array(a_list)\n",
    "b_array = np.array(b_list)\n",
    "\n",
    "# 스칼라 연산 시간\n",
    "start = time.time()\n",
    "result_scalar = scalar_add(a_list, b_list)\n",
    "scalar_time = time.time() - start\n",
    "\n",
    "# 벡터 연산 시간\n",
    "start = time.time()\n",
    "result_vector = vector_add(a_array, b_array)\n",
    "vector_time = time.time() - start\n",
    "\n",
    "print(f\"🐌 스칼라 연산: {scalar_time:.4f}초\")\n",
    "print(f\"🚀 벡터 연산: {vector_time:.4f}초\")\n",
    "print(f\"⚡ 속도 향상: {scalar_time/vector_time:.1f}배 빠름!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Broadcasting 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📍 예제 1: 스칼라 + 벡터\n",
      "  [1 2 3] + 10 = [11 12 13]\n",
      "\n",
      "📍 예제 2: 행렬 + 벡터 (행 방향)\n",
      "  행렬:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "  벡터: [10 20 30]\n",
      "  결과:\n",
      "[[11 22 33]\n",
      " [14 25 36]]\n",
      "\n",
      "📍 예제 3: 행렬 + 벡터 (열 방향)\n",
      "  행렬:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "  벡터:\n",
      "[[10]\n",
      " [20]]\n",
      "  결과:\n",
      "[[11 12 13]\n",
      " [24 25 26]]\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting 예제 1: 스칼라와 벡터\n",
    "print(\"📍 예제 1: 스칼라 + 벡터\")\n",
    "a = np.array([1, 2, 3])\n",
    "b = 10\n",
    "result = a + b\n",
    "print(f\"  {a} + {b} = {result}\")\n",
    "print()\n",
    "\n",
    "# Broadcasting 예제 2: 벡터와 행렬\n",
    "print(\"📍 예제 2: 행렬 + 벡터 (행 방향)\")\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6]])\n",
    "vector = np.array([10, 20, 30])\n",
    "result = matrix + vector\n",
    "print(f\"  행렬:\\n{matrix}\")\n",
    "print(f\"  벡터: {vector}\")\n",
    "print(f\"  결과:\\n{result}\")\n",
    "print()\n",
    "\n",
    "# Broadcasting 예제 3: 열 방향\n",
    "print(\"📍 예제 3: 행렬 + 벡터 (열 방향)\")\n",
    "vector_col = np.array([[10], [20]])\n",
    "result = matrix + vector_col\n",
    "print(f\"  행렬:\\n{matrix}\")\n",
    "print(f\"  벡터:\\n{vector_col}\")\n",
    "print(f\"  결과:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Broadcasting 분석\n",
      "==============================\n",
      "Shape A: (2, 3)\n",
      "Shape B: (3,)\n",
      "\n",
      "정렬 후:\n",
      "  A: (2, 3)\n",
      "  B: (1, 3)\n",
      "\n",
      "✅ 결과 Shape: (2, 3)\n",
      "\n",
      "==============================\n",
      "Shape A: (2, 1)\n",
      "Shape B: (1, 3)\n",
      "\n",
      "정렬 후:\n",
      "  A: (2, 1)\n",
      "  B: (1, 3)\n",
      "\n",
      "✅ 결과 Shape: (2, 3)\n",
      "\n",
      "==============================\n",
      "Shape A: (2, 3)\n",
      "Shape B: (4,)\n",
      "\n",
      "정렬 후:\n",
      "  A: (2, 3)\n",
      "  B: (1, 4)\n",
      "\n",
      "❌ Broadcasting 불가능: 3 != 4\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting 시각화\n",
    "def visualize_broadcasting(a_shape, b_shape):\n",
    "    \"\"\"Broadcasting 과정 시각화\"\"\"\n",
    "    print(f\"Shape A: {a_shape}\")\n",
    "    print(f\"Shape B: {b_shape}\")\n",
    "    \n",
    "    # 차원 맞추기\n",
    "    ndim = max(len(a_shape), len(b_shape))\n",
    "    a_shape = (1,) * (ndim - len(a_shape)) + a_shape\n",
    "    b_shape = (1,) * (ndim - len(b_shape)) + b_shape\n",
    "    \n",
    "    print(f\"\\n정렬 후:\")\n",
    "    print(f\"  A: {a_shape}\")\n",
    "    print(f\"  B: {b_shape}\")\n",
    "    \n",
    "    # Broadcasting 가능 여부 확인\n",
    "    result_shape = []\n",
    "    for a, b in zip(a_shape, b_shape):\n",
    "        if a == 1:\n",
    "            result_shape.append(b)\n",
    "        elif b == 1:\n",
    "            result_shape.append(a)\n",
    "        elif a == b:\n",
    "            result_shape.append(a)\n",
    "        else:\n",
    "            print(f\"\\n❌ Broadcasting 불가능: {a} != {b}\")\n",
    "            return\n",
    "    \n",
    "    print(f\"\\n✅ 결과 Shape: {tuple(result_shape)}\")\n",
    "\n",
    "# 테스트\n",
    "print(\"🔍 Broadcasting 분석\")\n",
    "print(\"=\" * 30)\n",
    "visualize_broadcasting((2, 3), (3,))\n",
    "print(\"\\n\" + \"=\" * 30)\n",
    "visualize_broadcasting((2, 1), (1, 3))\n",
    "print(\"\\n\" + \"=\" * 30)\n",
    "visualize_broadcasting((2, 3), (4,))  # 실패 케이스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 활성화 함수 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.         -4.8989899  -4.7979798  -4.6969697  -4.5959596  -4.49494949\n",
      " -4.39393939 -4.29292929 -4.19191919 -4.09090909 -3.98989899 -3.88888889\n",
      " -3.78787879 -3.68686869 -3.58585859 -3.48484848 -3.38383838 -3.28282828\n",
      " -3.18181818 -3.08080808 -2.97979798 -2.87878788 -2.77777778 -2.67676768\n",
      " -2.57575758 -2.47474747 -2.37373737 -2.27272727 -2.17171717 -2.07070707\n",
      " -1.96969697 -1.86868687 -1.76767677 -1.66666667 -1.56565657 -1.46464646\n",
      " -1.36363636 -1.26262626 -1.16161616 -1.06060606 -0.95959596 -0.85858586\n",
      " -0.75757576 -0.65656566 -0.55555556 -0.45454545 -0.35353535 -0.25252525\n",
      " -0.15151515 -0.05050505  0.05050505  0.15151515  0.25252525  0.35353535\n",
      "  0.45454545  0.55555556  0.65656566  0.75757576  0.85858586  0.95959596\n",
      "  1.06060606  1.16161616  1.26262626  1.36363636  1.46464646  1.56565657\n",
      "  1.66666667  1.76767677  1.86868687  1.96969697  2.07070707  2.17171717\n",
      "  2.27272727  2.37373737  2.47474747  2.57575758  2.67676768  2.77777778\n",
      "  2.87878788  2.97979798  3.08080808  3.18181818  3.28282828  3.38383838\n",
      "  3.48484848  3.58585859  3.68686869  3.78787879  3.88888889  3.98989899\n",
      "  4.09090909  4.19191919  4.29292929  4.39393939  4.49494949  4.5959596\n",
      "  4.6969697   4.7979798   4.8989899   5.        ]\n",
      "\n",
      "📊 ReLU\n",
      "  1.0 ┤\n",
      "  5.0 ┤│                    \n",
      "      │                   █\n",
      "      │                  ██\n",
      "      │                 ███\n",
      "      │                ████\n",
      "  0.0 ┤│               █████\n",
      "      │              ██████\n",
      "      │             ███████\n",
      "      │            ████████\n",
      "      │           █████████\n",
      "  0.0 ┤│████████████████████\n",
      "      └────────────────────\n",
      "       -5              5\n",
      "\n",
      "📊 Sigmoid\n",
      "  1.0 ┤\n",
      "  1.0 ┤│                    \n",
      "      │               █████\n",
      "      │             ███████\n",
      "      │            ████████\n",
      "      │           █████████\n",
      "  0.0 ┤│          ██████████\n",
      "      │          ██████████\n",
      "      │         ███████████\n",
      "      │        ████████████\n",
      "      │      ██████████████\n",
      "  0.0 ┤│████████████████████\n",
      "      └────────────────────\n",
      "       -5              5\n",
      "\n",
      "📊 Tanh\n",
      "  1.0 ┤\n",
      "  1.0 ┤│                    \n",
      "      │             ███████\n",
      "      │            ████████\n",
      "      │           █████████\n",
      "      │           █████████\n",
      "  0.0 ┤│          ██████████\n",
      "      │          ██████████\n",
      "      │          ██████████\n",
      "      │         ███████████\n",
      "      │        ████████████\n",
      "  -1.0 ┤│████████████████████\n",
      "      └────────────────────\n",
      "       -5              5\n"
     ]
    }
   ],
   "source": [
    "# 활성화 함수 비교\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "\n",
    "# 각 활성화 함수 적용\n",
    "y_relu = relu(x)\n",
    "y_sigmoid = sigmoid(x)\n",
    "y_tanh = np.tanh(x)\n",
    "\n",
    "# 텍스트 그래프로 시각화\n",
    "def plot_text_graph(y, title):\n",
    "    \"\"\"간단한 텍스트 그래프\"\"\"\n",
    "    print(f\"\\n📊 {title}\")\n",
    "    print(\"  1.0 ┤\")\n",
    "    \n",
    "    height = 10\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    \n",
    "    for h in range(height, -1, -1):\n",
    "        threshold = y_min + (y_max - y_min) * h / height\n",
    "        line = \"      │\"\n",
    "        \n",
    "        for val in y[::5]:  # 샘플링\n",
    "            if val >= threshold:\n",
    "                line += \"█\"\n",
    "            else:\n",
    "                line += \" \"\n",
    "        \n",
    "        if h == height:\n",
    "            print(f\"  {y_max:3.1f} ┤\" + line[6:])\n",
    "        elif h == 0:\n",
    "            print(f\"  {y_min:3.1f} ┤\" + line[6:])\n",
    "        elif h == height // 2:\n",
    "            print(f\"  0.0 ┤\" + line[6:])\n",
    "        else:\n",
    "            print(line)\n",
    "    \n",
    "    print(\"      └\" + \"─\" * 20)\n",
    "    print(\"       -5\" + \" \" * 14 + \"5\")\n",
    "\n",
    "plot_text_graph(y_relu, \"ReLU\")\n",
    "plot_text_graph(y_sigmoid, \"Sigmoid\")\n",
    "plot_text_graph(y_tanh, \"Tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Softmax 구현 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Softmax 함수 테스트\n",
      "========================================\n",
      "입력 (logits):\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [3 2 1]]\n",
      "\n",
      "출력 (probabilities):\n",
      "[[0.09  0.245 0.665]\n",
      " [0.09  0.245 0.665]\n",
      " [0.665 0.245 0.09 ]]\n",
      "\n",
      "각 행의 합:\n",
      "[1. 1. 1.]\n",
      "\n",
      "🔒 수치 안정성 테스트\n",
      "큰 값 입력: [1000 1001 1002]\n",
      "안정적인 출력: [0.09003057 0.24472847 0.66524096]\n",
      "합: 0.9999999999999999\n",
      "NaN 체크: False\n"
     ]
    }
   ],
   "source": [
    "# Softmax 테스트\n",
    "print(\"🎯 Softmax 함수 테스트\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 간단한 예제\n",
    "logits = np.array([[1, 2, 3],\n",
    "                   [1, 2, 3],\n",
    "                   [3, 2, 1]])\n",
    "\n",
    "probs = softmax(logits)\n",
    "\n",
    "print(\"입력 (logits):\")\n",
    "print(logits)\n",
    "print(\"\\n출력 (probabilities):\")\n",
    "print(np.round(probs, 3))\n",
    "print(\"\\n각 행의 합:\")\n",
    "print(probs.sum(axis=1))\n",
    "\n",
    "# 수치 안정성 테스트\n",
    "print(\"\\n🔒 수치 안정성 테스트\")\n",
    "large_logits = np.array([[1000, 1001, 1002]])\n",
    "stable_probs = softmax(large_logits)\n",
    "print(f\"큰 값 입력: {large_logits[0]}\")\n",
    "print(f\"안정적인 출력: {stable_probs[0]}\")\n",
    "print(f\"합: {stable_probs.sum()}\")\n",
    "print(f\"NaN 체크: {np.any(np.isnan(stable_probs))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 배치 처리 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 DataLoader 테스트\n",
      "========================================\n",
      "(100, 10)\n",
      "(100,)\n",
      "len(X): 100\n",
      "X[0]: [-0.75479854 -0.08122968  1.14009243  0.32005746  0.56644043  0.271125\n",
      "  1.6494374   1.7401719  -0.58618837 -0.23527365]\n",
      "len(X[0]): 10\n",
      "\n",
      "\n",
      "총 샘플 수: 100\n",
      "배치 크기: 16\n",
      "총 배치 수: 7\n",
      "\n",
      "배치 1: X shape=(16, 10), y shape=(16,)\n",
      "배치 2: X shape=(16, 10), y shape=(16,)\n",
      "배치 3: X shape=(16, 10), y shape=(16,)\n"
     ]
    }
   ],
   "source": [
    "class SimpleDataLoader:\n",
    "    \"\"\"간단한 DataLoader 구현\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_samples = len(X)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = np.arange(self.n_samples)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        for start_idx in range(0, self.n_samples, self.batch_size):\n",
    "            batch_indices = indices[start_idx:start_idx + self.batch_size]\n",
    "            # print(batch_indices)\n",
    "            # print(self.X[batch_indices])\n",
    "            # print(self.y[batch_indices])\n",
    "            # print(\"\\n\")\n",
    "            yield self.X[batch_indices], self.y[batch_indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.n_samples + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "# 테스트\n",
    "print(\"📦 DataLoader 테스트\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 가상 데이터\n",
    "X = np.random.randn(100, 10)\n",
    "y = np.random.randint(0, 3, 100)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"len(X):\", len(X))\n",
    "print(\"X[0]:\", X[0])\n",
    "print(\"len(X[0]):\", len(X[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# DataLoader 생성\n",
    "dataloader = SimpleDataLoader(X, y, batch_size=16)\n",
    "\n",
    "print(f\"총 샘플 수: {len(X)}\")\n",
    "print(f\"배치 크기: 16\")\n",
    "print(f\"총 배치 수: {len(dataloader)}\")\n",
    "print()\n",
    "\n",
    "# 첫 3개 배치 확인\n",
    "for i, (X_batch, y_batch) in enumerate(dataloader):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    print(f\"배치 {i+1}: X shape={X_batch.shape}, y shape={y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 벡터화된 신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Linear Layer 테스트\n",
      "========================================\n",
      "입력 shape: (32, 10)\n",
      "출력 shape: (32, 5)\n",
      "가중치 shape: (10, 5)\n",
      "편향 shape: (5,)\n",
      "\n",
      "역전파:\n",
      "출력 그래디언트 shape: (32, 5)\n",
      "입력 그래디언트 shape: (32, 10)\n",
      "가중치 그래디언트 shape: (10, 5)\n",
      "편향 그래디언트 shape: (5,)\n"
     ]
    }
   ],
   "source": [
    "# 벡터화된 Linear Layer 테스트\n",
    "print(\"🔗 Linear Layer 테스트\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Layer 생성\n",
    "layer = LinearLayer(input_dim=10, output_dim=5, activation='relu')\n",
    "\n",
    "# 배치 입력\n",
    "X = np.random.randn(32, 10)  # 32개 샘플, 10차원\n",
    "\n",
    "# Forward pass\n",
    "output = layer.forward(X)\n",
    "print(f\"입력 shape: {X.shape}\")\n",
    "print(f\"출력 shape: {output.shape}\")\n",
    "print(f\"가중치 shape: {layer.W.shape}\")\n",
    "print(f\"편향 shape: {layer.b.shape}\")\n",
    "\n",
    "# Backward pass\n",
    "grad_output = np.random.randn(*output.shape)\n",
    "grad_input = layer.backward(grad_output)\n",
    "print(f\"\\n역전파:\")\n",
    "print(f\"출력 그래디언트 shape: {grad_output.shape}\")\n",
    "print(f\"입력 그래디언트 shape: {grad_input.shape}\")\n",
    "print(f\"가중치 그래디언트 shape: {layer.dW.shape}\")\n",
    "print(f\"편향 그래디언트 shape: {layer.db.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ MLP 테스트\n",
      "========================================\n",
      "모델 구조: 10 → 20 → 15 → 3\n",
      "레이어 수: 3\n",
      "\n",
      "입력 shape: (32, 10)\n",
      "출력 shape: (32, 3)\n",
      "\n",
      "확률 분포 shape: (32, 3)\n",
      "확률 합 (처음 5개): [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 전체 MLP 테스트\n",
    "print(\"🏗️ MLP 테스트\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# MLP 생성\n",
    "mlp = MLPVectorized(\n",
    "    input_dim=10,\n",
    "    hidden_dims=[20, 15],\n",
    "    output_dim=3\n",
    ")\n",
    "\n",
    "print(f\"모델 구조: 10 → 20 → 15 → 3\")\n",
    "print(f\"레이어 수: {len(mlp.layers)}\")\n",
    "\n",
    "# 배치 처리\n",
    "X = np.random.randn(32, 10)\n",
    "output = mlp.forward(X)\n",
    "print(f\"\\n입력 shape: {X.shape}\")\n",
    "print(f\"출력 shape: {output.shape}\")\n",
    "\n",
    "# Softmax 적용\n",
    "probs = mlp.predict_proba(X)\n",
    "print(f\"\\n확률 분포 shape: {probs.shape}\")\n",
    "print(f\"확률 합 (처음 5개): {probs.sum(axis=1)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. XOR 문제 해결 (벡터화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 XOR 문제 (벡터화된 신경망)\n",
      "========================================\n",
      "데이터:\n",
      "  [0 0] → 0\n",
      "  [0 1] → 1\n",
      "  [1 0] → 1\n",
      "  [1 1] → 0\n",
      "\n",
      "📈 학습 시작...\n",
      "Epoch    0: Loss=0.7683, Acc=0.75\n",
      "Epoch  200: Loss=0.4542, Acc=0.75\n",
      "Epoch  400: Loss=0.0665, Acc=1.00\n",
      "Epoch  600: Loss=0.0269, Acc=1.00\n",
      "Epoch  800: Loss=0.0162, Acc=1.00\n",
      "\n",
      "📊 최종 결과:\n",
      "  [0 0] → 예측: 0, 정답: 0 ✓\n",
      "  [0 1] → 예측: 1, 정답: 1 ✓\n",
      "  [1 0] → 예측: 1, 정답: 1 ✓\n",
      "  [1 1] → 예측: 0, 정답: 0 ✓\n",
      "\n",
      "최종 정확도: 100%\n"
     ]
    }
   ],
   "source": [
    "# XOR 데이터\n",
    "X_xor = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]])\n",
    "\n",
    "y_xor = np.array([0, 1, 1, 0])\n",
    "\n",
    "print(\"🎯 XOR 문제 (벡터화된 신경망)\")\n",
    "print(\"=\" * 40)\n",
    "print(\"데이터:\")\n",
    "for inputs, target in zip(X_xor, y_xor):\n",
    "    print(f\"  {inputs} → {target}\")\n",
    "\n",
    "# 모델 생성\n",
    "xor_model = MLPVectorized(\n",
    "    input_dim=2,\n",
    "    hidden_dims=[4],\n",
    "    output_dim=2  # 이진 분류를 2-class로\n",
    ")\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = SGDOptimizer(xor_model, learning_rate=0.5)\n",
    "\n",
    "# 학습\n",
    "print(\"\\n📈 학습 시작...\")\n",
    "for epoch in range(1000):\n",
    "    # Forward\n",
    "    logits = xor_model.forward(X_xor)\n",
    "    probs = softmax(logits)\n",
    "    \n",
    "    # Loss\n",
    "    loss = cross_entropy(probs, y_xor)\n",
    "    \n",
    "    # Backward\n",
    "    grad = probs.copy()\n",
    "    grad[np.arange(4), y_xor] -= 1\n",
    "    grad /= 4\n",
    "    \n",
    "    xor_model.backward(grad)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        acc = accuracy(probs, y_xor)\n",
    "        print(f\"Epoch {epoch:4d}: Loss={loss:.4f}, Acc={acc:.2f}\")\n",
    "\n",
    "# 최종 평가\n",
    "print(\"\\n📊 최종 결과:\")\n",
    "final_probs = xor_model.predict_proba(X_xor)\n",
    "predictions = np.argmax(final_probs, axis=1)\n",
    "\n",
    "for inputs, pred, target in zip(X_xor, predictions, y_xor):\n",
    "    symbol = \"✓\" if pred == target else \"✗\"\n",
    "    print(f\"  {inputs} → 예측: {pred}, 정답: {target} {symbol}\")\n",
    "\n",
    "final_acc = accuracy(predictions, y_xor)\n",
    "print(f\"\\n최종 정확도: {final_acc:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3  0.2  0.1]\n",
      " [ 0.1  0.3 -0.4]\n",
      " [ 0.2 -0.5  0.3]\n",
      " [-0.2  0.1  0.1]]\n",
      "[[-0.075  0.05   0.025]\n",
      " [ 0.025  0.075 -0.1  ]\n",
      " [ 0.05  -0.125  0.075]\n",
      " [-0.05   0.025  0.025]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "grad = np.array([[0.7, 0.2, 0.1],\n",
    "                 [0.1, 0.3, 0.6],\n",
    "                 [0.2, 0.5, 0.3],\n",
    "                 [0.8, 0.1, 0.1]])\n",
    "\n",
    "y_xor = np.array([0, 2, 1, 0])\n",
    "\n",
    "grad[np.arange(4), y_xor] -= 1\n",
    "print(grad)\n",
    "print(grad/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 성능 벤치마크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ 연산 성능 벤치마크\n",
      "==================================================\n",
      "\n",
      "📏 크기: 100\n",
      "  덧셈 - 벡터: 0.0004s, 스칼라: 0.0135s, 속도향상: 37.6x\n",
      "  행렬곱 - NumPy: 0.0003s\n",
      "\n",
      "📏 크기: 1000\n",
      "  덧셈 - 벡터: 0.0006s, 스칼라: 0.0936s, 속도향상: 148.8x\n",
      "  행렬곱 - NumPy: 0.0132s\n",
      "\n",
      "📏 크기: 10000\n",
      "  덧셈 - 벡터: 0.0022s, 스칼라: 0.9656s, 속도향상: 446.7x\n"
     ]
    }
   ],
   "source": [
    "def benchmark_operations():\n",
    "    \"\"\"다양한 연산의 성능 비교\"\"\"\n",
    "    \n",
    "    print(\"⚡ 연산 성능 벤치마크\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    sizes = [100, 1000, 10000]\n",
    "    \n",
    "    for size in sizes:\n",
    "        print(f\"\\n📏 크기: {size}\")\n",
    "        \n",
    "        # 데이터 준비\n",
    "        a = np.random.randn(size)\n",
    "        b = np.random.randn(size)\n",
    "        \n",
    "        # 1. 덧셈\n",
    "        start = time.time()\n",
    "        for _ in range(1000):\n",
    "            _ = a + b\n",
    "        vector_time = time.time() - start\n",
    "        \n",
    "        start = time.time()\n",
    "        for _ in range(1000):\n",
    "            _ = [a[i] + b[i] for i in range(size)]\n",
    "        scalar_time = time.time() - start\n",
    "        \n",
    "        print(f\"  덧셈 - 벡터: {vector_time:.4f}s, 스칼라: {scalar_time:.4f}s, 속도향상: {scalar_time/vector_time:.1f}x\")\n",
    "        \n",
    "        # 2. 행렬곱\n",
    "        if size <= 1000:  # 큰 크기는 시간이 너무 오래 걸림\n",
    "            A = np.random.randn(size, size)\n",
    "            B = np.random.randn(size, size)\n",
    "            \n",
    "            start = time.time()\n",
    "            _ = A @ B\n",
    "            vector_time = time.time() - start\n",
    "            \n",
    "            print(f\"  행렬곱 - NumPy: {vector_time:.4f}s\")\n",
    "\n",
    "benchmark_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Batch Normalization 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Batch Normalization 테스트\n",
      "========================================\n",
      "원본 데이터:\n",
      "  평균: 3.26\n",
      "  표준편차: 5.09\n",
      "\n",
      "정규화 후:\n",
      "  평균: 0.0000\n",
      "  표준편차: 1.0000\n",
      "\n",
      "특성별 통계 (처음 5개):\n",
      "  특성 0: 평균=0.0000, 분산=1.0000\n",
      "  특성 1: 평균=0.0000, 분산=1.0000\n",
      "  특성 2: 평균=0.0000, 분산=1.0000\n",
      "  특성 3: 평균=0.0000, 분산=1.0000\n",
      "  특성 4: 평균=-0.0000, 분산=1.0000\n"
     ]
    }
   ],
   "source": [
    "# Batch Normalization 효과 확인\n",
    "print(\"🔄 Batch Normalization 테스트\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 입력 데이터 (평균과 분산이 다양함)\n",
    "X = np.random.randn(32, 10) * 5 + 3  # 평균 3, 표준편차 5\n",
    "\n",
    "print(f\"원본 데이터:\")\n",
    "print(f\"  평균: {X.mean():.2f}\")\n",
    "print(f\"  표준편차: {X.std():.2f}\")\n",
    "\n",
    "# Batch Norm 적용\n",
    "gamma = np.ones(10)\n",
    "beta = np.zeros(10)\n",
    "\n",
    "X_norm, (mean, var) = batch_norm(X, gamma, beta, training=True)\n",
    "\n",
    "print(f\"\\n정규화 후:\")\n",
    "print(f\"  평균: {X_norm.mean():.4f}\")\n",
    "print(f\"  표준편차: {X_norm.std():.4f}\")\n",
    "\n",
    "# 각 특성별 통계\n",
    "print(f\"\\n특성별 통계 (처음 5개):\")\n",
    "for i in range(min(5, X.shape[1])):\n",
    "    print(f\"  특성 {i}: 평균={X_norm[:, i].mean():.4f}, 분산={X_norm[:, i].var():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 손실 함수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 손실 함수 비교\n",
      "========================================\n",
      "\n",
      "회귀 손실:\n",
      "  MSE Loss: 0.0450\n",
      "\n",
      "분류 손실:\n",
      "  Cross Entropy: 0.3284\n",
      "  Accuracy: 100.00%\n",
      "\n",
      "극단적인 경우:\n",
      "  완벽한 예측 CE: 0.000000\n",
      "  랜덤 예측 CE: 1.0986\n"
     ]
    }
   ],
   "source": [
    "# 다양한 손실 함수 비교\n",
    "print(\"📉 손실 함수 비교\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 회귀용 데이터\n",
    "y_true_reg = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "y_pred_reg = np.array([1.2, 2.3, 2.8, 4.1])\n",
    "\n",
    "mse = mse_loss(y_pred_reg, y_true_reg)\n",
    "print(f\"\\n회귀 손실:\")\n",
    "print(f\"  MSE Loss: {mse:.4f}\")\n",
    "\n",
    "# 분류용 데이터\n",
    "y_true_cls = np.array([0, 1, 2, 1])\n",
    "y_pred_cls = np.array([[0.8, 0.1, 0.1],\n",
    "                       [0.1, 0.7, 0.2],\n",
    "                       [0.2, 0.2, 0.6],\n",
    "                       [0.1, 0.8, 0.1]])\n",
    "\n",
    "ce = cross_entropy(y_pred_cls, y_true_cls)\n",
    "acc = accuracy(y_pred_cls, y_true_cls)\n",
    "\n",
    "print(f\"\\n분류 손실:\")\n",
    "print(f\"  Cross Entropy: {ce:.4f}\")\n",
    "print(f\"  Accuracy: {acc:.2%}\")\n",
    "\n",
    "# 완벽한 예측 vs 랜덤 예측\n",
    "print(f\"\\n극단적인 경우:\")\n",
    "\n",
    "# 완벽한 예측\n",
    "y_perfect = np.array([[1, 0, 0],\n",
    "                      [0, 1, 0],\n",
    "                      [0, 0, 1]])\n",
    "y_true_perfect = np.array([0, 1, 2])\n",
    "ce_perfect = cross_entropy(y_perfect, y_true_perfect)\n",
    "print(f\"  완벽한 예측 CE: {ce_perfect:.6f}\")\n",
    "\n",
    "# 균등 분포 (랜덤)\n",
    "y_random = np.ones((3, 3)) / 3\n",
    "ce_random = cross_entropy(y_random, y_true_perfect)\n",
    "print(f\"  랜덤 예측 CE: {ce_random:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 메모리 효율성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 메모리 효율성 비교\n",
      "========================================\n",
      "배열 크기: (10000, 100)\n",
      "\n",
      "Broadcasting:\n",
      "  시간: 0.0011초\n",
      "  메모리: b는 (100,) 유지\n",
      "\n",
      "Explicit 복사:\n",
      "  시간: 0.0023초\n",
      "  메모리: b_repeated는 (10000, 100)\n",
      "\n",
      "효율성: 2.2배 빠름!\n",
      "\n",
      "결과 동일: True\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting vs Explicit 복사\n",
    "print(\"💾 메모리 효율성 비교\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "size = 10000\n",
    "a = np.random.randn(size, 100)\n",
    "b = np.random.randn(100)\n",
    "\n",
    "# Broadcasting (효율적)\n",
    "start = time.time()\n",
    "result1 = a + b  # b가 자동으로 broadcast\n",
    "broadcast_time = time.time() - start\n",
    "\n",
    "# Explicit 복사 (비효율적)\n",
    "start = time.time()\n",
    "b_repeated = np.tile(b, (size, 1))\n",
    "result2 = a + b_repeated\n",
    "explicit_time = time.time() - start\n",
    "\n",
    "print(f\"배열 크기: {a.shape}\")\n",
    "print(f\"\\nBroadcasting:\")\n",
    "print(f\"  시간: {broadcast_time:.4f}초\")\n",
    "print(f\"  메모리: b는 (100,) 유지\")\n",
    "\n",
    "print(f\"\\nExplicit 복사:\")\n",
    "print(f\"  시간: {explicit_time:.4f}초\")\n",
    "print(f\"  메모리: b_repeated는 {b_repeated.shape}\")\n",
    "\n",
    "print(f\"\\n효율성: {explicit_time/broadcast_time:.1f}배 빠름!\")\n",
    "\n",
    "# 결과 동일성 확인\n",
    "print(f\"\\n결과 동일: {np.allclose(result1, result2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 축하합니다!\n",
    "\n",
    "벡터화된 연산의 힘을 경험하셨습니다!\n",
    "\n",
    "### 핵심 교훈:\n",
    "1. **벡터화는 필수**: 10배 이상의 속도 향상\n",
    "2. **Broadcasting 활용**: 메모리 효율적인 연산\n",
    "3. **Batch 처리**: 병렬 연산으로 처리량 증가\n",
    "4. **수치 안정성**: 오버플로우/언더플로우 방지\n",
    "\n",
    "### 다음 단계:\n",
    "- `50_eval/mnist_mini.py` 실행하여 실제 데이터셋 학습\n",
    "- `50_eval/benchmark.py` 실행하여 성능 비교\n",
    "- Day 3: Attention Mechanism으로 진행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
