"""
ğŸ§ª Tensor Operations í…ŒìŠ¤íŠ¸
"""

import pytest
import numpy as np
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))

from core.tensor_ops import (
    matmul, relu, sigmoid, softmax,
    mse_loss, cross_entropy, batch_norm,
    one_hot, accuracy
)


class TestActivations:
    """í™œì„±í™” í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    
    def test_relu(self):
        x = np.array([-2, -1, 0, 1, 2])
        result = relu(x)
        expected = np.array([0, 0, 0, 1, 2])
        np.testing.assert_array_equal(result, expected)
    
    def test_sigmoid(self):
        x = np.array([0])
        result = sigmoid(x)
        np.testing.assert_almost_equal(result, 0.5)
        
        # í° ê°’ í…ŒìŠ¤íŠ¸ (ì˜¤ë²„í”Œë¡œìš° ë°©ì§€)
        x = np.array([1000, -1000])
        result = sigmoid(x)
        assert result[0] > 0.99
        assert result[1] < 0.01
    
    def test_softmax(self):
        # 2D ë°°ì—´ í…ŒìŠ¤íŠ¸
        x = np.array([[1, 2, 3],
                      [1, 2, 3]])
        result = softmax(x)
        
        # ê° í–‰ì˜ í•©ì´ 1
        np.testing.assert_almost_equal(result.sum(axis=1), [1, 1])
        
        # ìˆ˜ì¹˜ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
        x = np.array([[1000, 1001, 1002]])
        result = softmax(x)
        assert not np.any(np.isnan(result))
        np.testing.assert_almost_equal(result.sum(), 1)


class TestLossFunctions:
    """ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    
    def test_mse_loss(self):
        y_pred = np.array([[1, 2], [3, 4]])
        y_true = np.array([[1, 2], [3, 4]])
        loss = mse_loss(y_pred, y_true)
        assert loss == 0
        
        y_pred = np.array([[1, 2], [3, 4]])
        y_true = np.array([[0, 0], [0, 0]])
        loss = mse_loss(y_pred, y_true)
        expected = (1 + 4 + 9 + 16) / 4
        np.testing.assert_almost_equal(loss, expected)
    
    def test_cross_entropy(self):
        # ì™„ë²½í•œ ì˜ˆì¸¡
        y_pred = np.array([[0, 1, 0],
                          [1, 0, 0],
                          [0, 0, 1]])
        y_true = np.array([1, 0, 2])
        loss = cross_entropy(y_pred, y_true)
        np.testing.assert_almost_equal(loss, 0, decimal=5)
        
        # ê· ë“± ë¶„í¬
        y_pred = np.array([[1/3, 1/3, 1/3],
                          [1/3, 1/3, 1/3]])
        y_true = np.array([0, 1])
        loss = cross_entropy(y_pred, y_true)
        expected = -np.log(1/3)
        np.testing.assert_almost_equal(loss, expected, decimal=5)


class TestBatchNorm:
    """ë°°ì¹˜ ì •ê·œí™” í…ŒìŠ¤íŠ¸"""
    
    def test_batch_norm_training(self):
        np.random.seed(42)
        x = np.random.randn(32, 10)
        gamma = np.ones(10)
        beta = np.zeros(10)
        
        x_norm, (mean, var) = batch_norm(x, gamma, beta, training=True)
        
        # ì •ê·œí™” í›„ í‰ê· ì€ 0, ë¶„ì‚°ì€ 1ì— ê°€ê¹Œì›Œì•¼ í•¨
        np.testing.assert_almost_equal(x_norm.mean(axis=0), np.zeros(10), decimal=5)
        np.testing.assert_almost_equal(x_norm.var(axis=0), np.ones(10), decimal=4)
    
    def test_batch_norm_inference(self):
        np.random.seed(42)
        x = np.random.randn(32, 10)
        gamma = np.ones(10)
        beta = np.zeros(10)
        
        # Running statistics
        running_mean = np.random.randn(10)
        running_var = np.random.rand(10) + 0.5
        
        x_norm, _ = batch_norm(
            x, gamma, beta,
            running_mean=running_mean,
            running_var=running_var,
            training=False
        )
        
        # ì¶”ë¡  ëª¨ë“œì—ì„œëŠ” running statistics ì‚¬ìš©
        expected = (x - running_mean) / np.sqrt(running_var + 1e-5)
        np.testing.assert_almost_equal(x_norm, expected)


class TestUtilities:
    """ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    
    def test_one_hot(self):
        indices = np.array([0, 2, 1, 0])
        result = one_hot(indices, num_classes=3)
        expected = np.array([[1, 0, 0],
                            [0, 0, 1],
                            [0, 1, 0],
                            [1, 0, 0]])
        np.testing.assert_array_equal(result, expected)
    
    def test_accuracy(self):
        # í™•ë¥ ì—ì„œ ì •í™•ë„
        y_pred = np.array([[0.1, 0.9, 0],
                          [0.8, 0.1, 0.1],
                          [0.2, 0.3, 0.5]])
        y_true = np.array([1, 0, 2])
        acc = accuracy(y_pred, y_true)
        assert acc == 1.0
        
        # í´ë˜ìŠ¤ì—ì„œ ì •í™•ë„
        y_pred = np.array([1, 0, 2])
        y_true = np.array([1, 1, 2])
        acc = accuracy(y_pred, y_true)
        np.testing.assert_almost_equal(acc, 2/3)


class TestMatrixOps:
    """í–‰ë ¬ ì—°ì‚° í…ŒìŠ¤íŠ¸"""
    
    def test_matmul(self):
        A = np.array([[1, 2], [3, 4]])
        B = np.array([[5, 6], [7, 8]])
        result = matmul(A, B)
        expected = np.array([[19, 22], [43, 50]])
        np.testing.assert_array_equal(result, expected)
        
        # Batch matmul
        A = np.random.randn(32, 10, 20)
        B = np.random.randn(32, 20, 30)
        result = matmul(A, B)
        assert result.shape == (32, 10, 30)


if __name__ == "__main__":
    pytest.main([__file__, "-v"])