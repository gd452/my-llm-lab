"""
ğŸ¯ XOR Problem: ì‹ ê²½ë§ì˜ Hello World

XOR (Exclusive OR) ë¬¸ì œëŠ” ì‹ ê²½ë§ í•™ìŠµì˜ ê³ ì „ì ì¸ ì˜ˆì œì…ë‹ˆë‹¤.
ë‹¨ìˆœí•œ ì„ í˜• ë¶„ë¥˜ê¸°ë¡œëŠ” í•´ê²°í•  ìˆ˜ ì—†ì–´, ì€ë‹‰ì¸µì´ í•„ìš”í•©ë‹ˆë‹¤.

XOR ì§„ë¦¬í‘œ:
    ì…ë ¥ | ì¶œë ¥
    -----|-----
    0, 0 |  0
    0, 1 |  1
    1, 0 |  1  
    1, 1 |  0

ì´ íŒ¨í„´ì€ ì„ í˜•ìœ¼ë¡œ ë¶„ë¦¬ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤!
"""

# ë°©ë²• 1: pip install -e . ì„¤ì¹˜ í›„ (ê¶Œì¥)

from core.autograd import Value
from core.mlp import MLP
from core.losses import mse_loss
from core.optimizer import SGD


def create_xor_data():
    """
    XOR ë°ì´í„°ì…‹ ìƒì„±
    
    Returns:
        X: ì…ë ¥ ë°ì´í„°
        y: ëª©í‘œ ì¶œë ¥
    """
    # XOR ì…ë ¥
    X = [
        [0.0, 0.0],
        [0.0, 1.0],
        [1.0, 0.0],
        [1.0, 1.0]
    ]
    
    # XOR ì¶œë ¥
    y = [0.0, 1.0, 1.0, 0.0]
    
    return X, y


def train_xor(epochs=1000, lr=0.1, hidden_size=4, verbose=True):
    """
    XOR ë¬¸ì œë¥¼ í•™ìŠµí•˜ëŠ” ì‹ ê²½ë§
    
    Args:
        epochs: í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
        lr: í•™ìŠµë¥ 
        hidden_size: ì€ë‹‰ì¸µ í¬ê¸°
        verbose: ì¶œë ¥ ì—¬ë¶€
    
    TODO êµ¬í˜„ í›„ ì‘ë™:
    1. ë°ì´í„° ì¤€ë¹„
    2. ëª¨ë¸ ìƒì„± (2-hidden-1 êµ¬ì¡°)
    3. ìµœì í™”ê¸° ìƒì„±
    4. í•™ìŠµ ë£¨í”„:
       - Forward pass
       - Loss ê³„ì‚°
       - Backward pass
       - íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    """
    
    print("=" * 60)
    print("ğŸ¯ XOR Problem Solver")
    print("=" * 60)
    
    # ë°ì´í„° ì¤€ë¹„
    X, y = create_xor_data()
    print(f"\nğŸ“Š ë°ì´í„°:")
    for i, (inputs, target) in enumerate(zip(X, y)):
        print(f"  {inputs} â†’ {target}")
    
    # ëª¨ë¸ ìƒì„±
    model = MLP(2, [hidden_size, 1])  # 2-4-1 êµ¬ì¡°
    print(f"\nğŸ—ï¸ ëª¨ë¸ êµ¬ì¡°: 2-{hidden_size}-1")
    model.summary()
    
    # ìµœì í™”ê¸°
    optimizer = SGD(model.parameters(), lr=lr)
    print(f"\nâš™ï¸ ìµœì í™”: SGD (lr={lr})")
    
    # í•™ìŠµ
    print(f"\nğŸ“ˆ í•™ìŠµ ì‹œì‘ (epochs={epochs})...")
    print("-" * 40)
    
    history = []
    
    for epoch in range(epochs):
        # Forward pass - ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´
        predictions = []
        targets = []
        
        for inputs, target in zip(X, y):
            # Value ê°ì²´ë¡œ ë³€í™˜
            x_vals = [Value(x) for x in inputs]
            y_val = Value(target)
            
            # ì˜ˆì¸¡
            pred = model(x_vals)
            predictions.append(pred)
            targets.append(y_val)
        
        # Loss ê³„ì‚°
        loss = mse_loss(predictions, targets)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        
        # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        optimizer.step()
        
        # ê¸°ë¡
        history.append(loss.data)
        
        # ì¶œë ¥
        if verbose and (epoch % 100 == 0 or epoch == epochs - 1):
            print(f"Epoch {epoch:4d}: Loss = {loss.data:.6f}")
        
    
    print("-" * 40)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    
    # ìµœì¢… í‰ê°€
    print("\nğŸ“Š ìµœì¢… ê²°ê³¼:")
    print("-" * 40)
    correct = 0
    
    for inputs, target in zip(X, y):
        x_vals = [Value(x) for x in inputs]
        pred = model(x_vals)
        pred_val = pred.data
        
        # 0.5ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜
        pred_class = 1 if pred_val > 0.5 else 0
        is_correct = pred_class == int(target)
        correct += is_correct
        
        symbol = "âœ“" if is_correct else "âœ—"
        print(f"  {inputs} â†’ {pred_val:.4f} (ì˜ˆì¸¡: {pred_class}, ì •ë‹µ: {int(target)}) {symbol}")
    
    accuracy = correct / len(X) * 100
    print("-" * 40)
    print(f"ğŸ¯ ì •í™•ë„: {accuracy:.1f}% ({correct}/{len(X)})")

    
    # í•™ìŠµ ê³¡ì„  ì‹œê°í™” (ì„ íƒ)
    if verbose:
        print("\nğŸ“ˆ í•™ìŠµ ê³¡ì„ :")
        print("  Loss")
        print("  â†‘")
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê·¸ë˜í”„
        max_loss = max(history)
        height = 10
        width = min(50, len(history))
        step = len(history) // width
        
        for h in range(height, -1, -1):
            line = "  â”‚"
            for i in range(0, len(history), step):
                if history[i] / max_loss * height >= h:
                    line += "â–ˆ"
                else:
                    line += " "
            print(line)
        print("  â””" + "â”€" * width + "â†’ Epoch")
        print(f"    0{' ' * (width - 5)}{epochs}")
    
    return model, history
    


def visualize_decision_boundary(model):
    """
    ê²°ì • ê²½ê³„ ì‹œê°í™” (ì„ íƒ êµ¬í˜„)
    
    2D ê³µê°„ì—ì„œ ëª¨ë¸ì˜ ê²°ì • ê²½ê³„ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    # TODO: ì„ íƒ êµ¬í˜„
    pass


if __name__ == "__main__":
    # XOR ë¬¸ì œ í•´ê²°
    model, history = train_xor(
        epochs=1000,
        lr=0.1,
        hidden_size=4,
        verbose=True
    )
    
    # ì„±ê³µ ë©”ì‹œì§€
    if model:
        print("\n" + "ğŸ‰" * 20)
        print("ì¶•í•˜í•©ë‹ˆë‹¤! XOR ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤!")
        print("ì´ì œ ë” ë³µì¡í•œ ë¬¸ì œì— ë„ì „í•´ë³´ì„¸ìš”!")
        print("ğŸ‰" * 20)