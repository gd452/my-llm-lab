"""
í•™ìŠµëœ miniGPT ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
ë‹¤ì–‘í•œ ìƒì„± ì „ëµ ì‹¤í—˜ ê°€ëŠ¥
"""

import torch
from model import GPT
import argparse
import os

def load_model(model_path='outputs/model.pt'):
    """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
    
    # í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì„¤ì •
    vocab_size = 65  # ì…°ìµìŠ¤í”¼ì–´ í…ìŠ¤íŠ¸ì˜ ê³ ìœ  ë¬¸ì ìˆ˜
    n_embd = 384
    block_size = 256
    n_head = 6
    n_layer = 6
    dropout = 0.0  # ìƒì„± ì‹œì—ëŠ” dropout ì‚¬ìš© ì•ˆ í•¨
    
    # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = GPT(vocab_size, n_embd, block_size, n_head, n_layer, dropout)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    model.to(device)
    
    return model, device

def get_tokenizer():
    """Character tokenizer ì¤€ë¹„"""
    # ì…°ìµìŠ¤í”¼ì–´ í…ìŠ¤íŠ¸ì—ì„œ vocabulary ì¬êµ¬ì„±
    with open('data/shakespeare.txt', 'r', encoding='utf-8') as f:
        text = f.read()
    
    chars = sorted(list(set(text)))
    stoi = {ch: i for i, ch in enumerate(chars)}
    itos = {i: ch for i, ch in enumerate(chars)}
    
    encode = lambda s: [stoi[c] for c in s]
    decode = lambda l: ''.join([itos[i] for i in l])
    
    return encode, decode, stoi

def generate_text(model, device, prompt, max_new_tokens, temperature, top_k):
    """í…ìŠ¤íŠ¸ ìƒì„±"""
    
    encode, decode, stoi = get_tokenizer()
    
    # í”„ë¡¬í”„íŠ¸ ì¸ì½”ë”©
    if prompt:
        # í”„ë¡¬í”„íŠ¸ì˜ ë¬¸ìê°€ vocabularyì— ìˆëŠ”ì§€ í™•ì¸
        for char in prompt:
            if char not in stoi:
                print(f"ê²½ê³ : '{char}'ëŠ” vocabularyì— ì—†ìŒ. ê³µë°±ìœ¼ë¡œ ëŒ€ì²´.")
                prompt = prompt.replace(char, ' ')
        
        context = torch.tensor(encode(prompt), dtype=torch.long, device=device).unsqueeze(0)
        print(f"\ní”„ë¡¬í”„íŠ¸: {prompt}")
    else:
        # ë¹ˆ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‹œì‘ (ì™„ì „ ììœ  ìƒì„±)
        context = torch.zeros((1, 1), dtype=torch.long, device=device)
        print("\ní”„ë¡¬í”„íŠ¸ ì—†ì´ ìƒì„± ì‹œì‘...")
    
    print(f"Temperature: {temperature}, Top-k: {top_k}")
    print("-" * 50)
    
    # ìƒì„±
    with torch.no_grad():
        generated = model.generate(
            context, 
            max_new_tokens=max_new_tokens,
            temperature=temperature,
            top_k=top_k
        )
    
    # ë””ì½”ë”© ë° ì¶œë ¥
    generated_text = decode(generated[0].tolist())
    return generated_text

def main():
    parser = argparse.ArgumentParser(description='miniGPT í…ìŠ¤íŠ¸ ìƒì„±')
    parser.add_argument('--prompt', type=str, default='', 
                       help='ì‹œì‘ í…ìŠ¤íŠ¸ (ë¹ˆ ë¬¸ìì—´ì´ë©´ ì²˜ìŒë¶€í„° ìƒì„±)')
    parser.add_argument('--length', type=int, default=500,
                       help='ìƒì„±í•  í† í° ìˆ˜ (ê¸°ë³¸: 500)')
    parser.add_argument('--temperature', type=float, default=0.8,
                       help='ìƒì„± ë‹¤ì–‘ì„± (0.1=ë³´ìˆ˜ì , 1.0=ê· í˜•, 2.0=ì°½ì˜ì )')
    parser.add_argument('--top_k', type=int, default=40,
                       help='Top-k ìƒ˜í”Œë§ (ì‘ì„ìˆ˜ë¡ ì•ˆì „, í´ìˆ˜ë¡ ë‹¤ì–‘)')
    parser.add_argument('--model', type=str, default='outputs/model.pt',
                       help='ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # ëª¨ë¸ ì²´í¬
    if not os.path.exists(args.model):
        print(f"ì—ëŸ¬: ëª¨ë¸ íŒŒì¼ '{args.model}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € 'python train.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ì„¸ìš”.")
        return
    
    # ëª¨ë¸ ë¡œë“œ
    print("ëª¨ë¸ ë¡œë”© ì¤‘...")
    model, device = load_model(args.model)
    
    # í…ìŠ¤íŠ¸ ìƒì„±
    generated = generate_text(
        model, device,
        prompt=args.prompt,
        max_new_tokens=args.length,
        temperature=args.temperature,
        top_k=args.top_k
    )
    
    print(generated)
    print("-" * 50)
    
    # ìƒì„± ì˜µì…˜ ì‹¤í—˜ ì œì•ˆ
    if args.temperature == 0.8 and args.top_k == 40:
        print("\nğŸ’¡ ë‹¤ë¥¸ ì„¤ì •ë„ ì‹œë„í•´ë³´ì„¸ìš”:")
        print("  - ë³´ìˆ˜ì : --temperature 0.5 --top_k 10")
        print("  - ì°½ì˜ì : --temperature 1.2 --top_k 100")
        print("  - ê·¹ë‹¨ì : --temperature 2.0 --top_k 200")

if __name__ == '__main__':
    main()