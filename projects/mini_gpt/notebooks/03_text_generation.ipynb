{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Text Generation - GPT가 텍스트를 생성하는 방법\n",
    "\n",
    "이 노트북에서는 **GPT가 어떻게 텍스트를 생성하는지** 단계별로 이해합니다.\n",
    "\n",
    "## 핵심 개념\n",
    "- Autoregressive generation (자기회귀 생성)\n",
    "- Temperature sampling\n",
    "- Top-k, Top-p sampling\n",
    "- Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Autoregressive Generation 이해\n",
    "\n",
    "**핵심**: 한 번에 한 토큰씩 생성, 이전 출력이 다음 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 vocabulary\n",
    "vocab = ['<PAD>', 'The', 'cat', 'sat', 'on', 'the', 'mat', '.', 'dog', 'ran']\n",
    "vocab_size = len(vocab)\n",
    "stoi = {ch: i for i, ch in enumerate(vocab)}  # string to int\n",
    "itos = {i: ch for i, ch in enumerate(vocab)}  # int to string\n",
    "\n",
    "print(\"Vocabulary:\")\n",
    "for i, word in enumerate(vocab):\n",
    "    print(f\"  {i}: {word}\")\n",
    "\n",
    "# 시작 토큰\n",
    "context = [stoi['The']]  # \"The\"로 시작\n",
    "print(f\"\\n시작 context: {[itos[i] for i in context]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 다음 토큰 예측 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가상의 모델 출력 (logits)\n",
    "# 실제로는 GPT가 예측하지만, 여기서는 수동으로 설정\n",
    "def mock_gpt_prediction(context):\n",
    "    \"\"\"주어진 context에서 다음 토큰 확률 반환 (가상)\"\"\"\n",
    "    # 실제로는 model(context)로 계산\n",
    "    logits = torch.randn(vocab_size)\n",
    "    \n",
    "    # 문법적으로 가능한 패턴 강조 (예시)\n",
    "    if context[-1] == stoi['The']:\n",
    "        logits[stoi['cat']] += 3\n",
    "        logits[stoi['dog']] += 2\n",
    "    elif context[-1] == stoi['cat']:\n",
    "        logits[stoi['sat']] += 3\n",
    "        logits[stoi['ran']] += 1\n",
    "    elif context[-1] == stoi['sat']:\n",
    "        logits[stoi['on']] += 4\n",
    "    \n",
    "    return logits\n",
    "\n",
    "# 예측\n",
    "logits = mock_gpt_prediction(context)\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# 확률 시각화\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(vocab_size), probs.numpy())\n",
    "plt.xlabel('Token ID')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Next Token Probabilities after \"The\"')\n",
    "plt.xticks(range(vocab_size), vocab, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 3 확률\n",
    "top_probs, top_indices = torch.topk(probs, 3)\n",
    "print(\"\\nTop 3 predictions:\")\n",
    "for prob, idx in zip(top_probs, top_indices):\n",
    "    print(f\"  {itos[idx.item()]:10} {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Greedy Decoding vs Sampling\n",
    "\n",
    "**Greedy**: 항상 가장 확률 높은 토큰 선택\n",
    "**Sampling**: 확률 분포에서 랜덤 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_greedy(start_context, num_tokens=5):\n",
    "    \"\"\"Greedy decoding: 항상 최고 확률 선택\"\"\"\n",
    "    context = start_context.copy()\n",
    "    \n",
    "    for _ in range(num_tokens):\n",
    "        logits = mock_gpt_prediction(context)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_token = torch.argmax(probs).item()\n",
    "        context.append(next_token)\n",
    "    \n",
    "    return context\n",
    "\n",
    "def generate_sampling(start_context, num_tokens=5):\n",
    "    \"\"\"Random sampling: 확률에 따라 샘플링\"\"\"\n",
    "    context = start_context.copy()\n",
    "    \n",
    "    for _ in range(num_tokens):\n",
    "        logits = mock_gpt_prediction(context)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, 1).item()\n",
    "        context.append(next_token)\n",
    "    \n",
    "    return context\n",
    "\n",
    "# 비교\n",
    "print(\"Greedy Decoding (결정적):\")\n",
    "for i in range(3):\n",
    "    result = generate_greedy([stoi['The']], 4)\n",
    "    print(f\"  {i+1}: {' '.join([itos[t] for t in result])}\")\n",
    "\n",
    "print(\"\\nRandom Sampling (다양함):\")\n",
    "for i in range(3):\n",
    "    result = generate_sampling([stoi['The']], 4)\n",
    "    print(f\"  {i+1}: {' '.join([itos[t] for t in result])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temperature Sampling\n",
    "\n",
    "Temperature로 확률 분포의 \"sharpness\" 조절:\n",
    "- **Low temperature (< 1.0)**: 더 확실한 선택\n",
    "- **High temperature (> 1.0)**: 더 다양한 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_temperature(logits, temperature):\n",
    "    \"\"\"Temperature를 적용한 logits\"\"\"\n",
    "    return logits / temperature\n",
    "\n",
    "# 다양한 temperature 비교\n",
    "logits = mock_gpt_prediction([stoi['The']])\n",
    "temperatures = [0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "\n",
    "for i, temp in enumerate(temperatures):\n",
    "    scaled_logits = apply_temperature(logits, temp)\n",
    "    probs = F.softmax(scaled_logits, dim=-1)\n",
    "    \n",
    "    axes[i].bar(range(vocab_size), probs.numpy())\n",
    "    axes[i].set_title(f'Temperature = {temp}')\n",
    "    axes[i].set_xlabel('Token')\n",
    "    axes[i].set_ylabel('Probability')\n",
    "    axes[i].set_xticks(range(vocab_size))\n",
    "    axes[i].set_xticklabels(vocab, rotation=45, ha='right')\n",
    "    \n",
    "    # Entropy 계산 (다양성 척도)\n",
    "    entropy = -(probs * torch.log(probs + 1e-8)).sum().item()\n",
    "    axes[i].text(0.5, 0.95, f'Entropy: {entropy:.2f}', \n",
    "                transform=axes[i].transAxes, ha='center')\n",
    "\n",
    "plt.suptitle('Effect of Temperature on Probability Distribution', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Temperature 효과:\")\n",
    "print(\"- 낮은 T (0.5): 확률 차이 증폭, 보수적 선택\")\n",
    "print(\"- 높은 T (2.0): 확률 평준화, 창의적 선택\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Top-k Sampling\n",
    "\n",
    "상위 k개 토큰 중에서만 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_sampling(logits, k=3, temperature=1.0):\n",
    "    \"\"\"Top-k 토큰 중에서만 샘플링\"\"\"\n",
    "    # Temperature 적용\n",
    "    logits = logits / temperature\n",
    "    \n",
    "    # Top-k 필터링\n",
    "    top_k_values, top_k_indices = torch.topk(logits, k)\n",
    "    \n",
    "    # 나머지는 -inf로 설정\n",
    "    filtered_logits = torch.full_like(logits, float('-inf'))\n",
    "    filtered_logits[top_k_indices] = top_k_values\n",
    "    \n",
    "    # Softmax & sampling\n",
    "    probs = F.softmax(filtered_logits, dim=-1)\n",
    "    next_token = torch.multinomial(probs, 1).item()\n",
    "    \n",
    "    return next_token, probs\n",
    "\n",
    "# Top-k 효과 시각화\n",
    "logits = mock_gpt_prediction([stoi['The']])\n",
    "k_values = [1, 3, 5, 10]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    _, probs = top_k_sampling(logits.clone(), k=k)\n",
    "    \n",
    "    axes[i].bar(range(vocab_size), probs.numpy())\n",
    "    axes[i].set_title(f'Top-{k} Sampling')\n",
    "    axes[i].set_xlabel('Token')\n",
    "    axes[i].set_ylabel('Probability')\n",
    "    axes[i].set_xticks(range(vocab_size))\n",
    "    axes[i].set_xticklabels(vocab, rotation=45, ha='right')\n",
    "    \n",
    "    # 실제 선택 가능한 토큰 수\n",
    "    num_possible = (probs > 0).sum().item()\n",
    "    axes[i].text(0.5, 0.95, f'Possible: {num_possible}', \n",
    "                transform=axes[i].transAxes, ha='center')\n",
    "\n",
    "plt.suptitle('Top-k Sampling Effect', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top-k 효과:\")\n",
    "print(\"- k=1: Greedy decoding과 동일\")\n",
    "print(\"- k=3: 상위 3개 중 선택 (안전하면서도 다양)\")\n",
    "print(\"- k=10: 거의 모든 토큰 가능 (원본과 유사)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Top-p (Nucleus) Sampling\n",
    "\n",
    "누적 확률이 p를 넘을 때까지의 토큰만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_p_sampling(logits, p=0.9, temperature=1.0):\n",
    "    \"\"\"누적 확률 p까지의 토큰만 사용\"\"\"\n",
    "    # Temperature & softmax\n",
    "    logits = logits / temperature\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    \n",
    "    # 확률 내림차순 정렬\n",
    "    sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "    \n",
    "    # p를 넘는 지점 찾기\n",
    "    cutoff_idx = torch.where(cumulative_probs > p)[0]\n",
    "    if len(cutoff_idx) > 0:\n",
    "        cutoff_idx = cutoff_idx[0].item()\n",
    "    else:\n",
    "        cutoff_idx = len(sorted_probs) - 1\n",
    "    \n",
    "    # 필터링\n",
    "    filtered_logits = torch.full_like(logits, float('-inf'))\n",
    "    selected_indices = sorted_indices[:cutoff_idx + 1]\n",
    "    filtered_logits[selected_indices] = logits[selected_indices]\n",
    "    \n",
    "    # 재정규화 & 샘플링\n",
    "    final_probs = F.softmax(filtered_logits, dim=-1)\n",
    "    next_token = torch.multinomial(final_probs, 1).item()\n",
    "    \n",
    "    return next_token, final_probs, cutoff_idx + 1\n",
    "\n",
    "# Top-p 효과 시각화\n",
    "p_values = [0.5, 0.7, 0.9, 0.99]\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "\n",
    "for i, p in enumerate(p_values):\n",
    "    _, probs, num_tokens = top_p_sampling(logits.clone(), p=p)\n",
    "    \n",
    "    axes[i].bar(range(vocab_size), probs.numpy())\n",
    "    axes[i].set_title(f'Top-p (p={p})')\n",
    "    axes[i].set_xlabel('Token')\n",
    "    axes[i].set_ylabel('Probability')\n",
    "    axes[i].set_xticks(range(vocab_size))\n",
    "    axes[i].set_xticklabels(vocab, rotation=45, ha='right')\n",
    "    axes[i].text(0.5, 0.95, f'Using {num_tokens} tokens', \n",
    "                transform=axes[i].transAxes, ha='center')\n",
    "\n",
    "plt.suptitle('Top-p (Nucleus) Sampling', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top-p 장점:\")\n",
    "print(\"- 동적 선택: 확률 분포에 따라 k가 자동 조절\")\n",
    "print(\"- 더 자연스러운 샘플링\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 전체 생성 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(start_tokens, max_new_tokens=10, \n",
    "             temperature=1.0, top_k=None, top_p=None):\n",
    "    \"\"\"\n",
    "    완전한 텍스트 생성 함수\n",
    "    \"\"\"\n",
    "    context = start_tokens.copy()\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        # 모델 예측 (가상)\n",
    "        logits = mock_gpt_prediction(context)\n",
    "        \n",
    "        # Temperature 적용\n",
    "        logits = logits / temperature\n",
    "        \n",
    "        # Top-k 필터링\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            logits[logits < v[-1]] = float('-inf')\n",
    "        \n",
    "        # Top-p 필터링\n",
    "        if top_p is not None:\n",
    "            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "            cumulative_probs = torch.cumsum(\n",
    "                F.softmax(sorted_logits, dim=-1), dim=-1\n",
    "            )\n",
    "            sorted_indices_to_remove = cumulative_probs > top_p\n",
    "            sorted_indices_to_remove[0] = False  # 최소 1개는 유지\n",
    "            indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "            logits[indices_to_remove] = float('-inf')\n",
    "        \n",
    "        # 확률 계산 & 샘플링\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        \n",
    "        context.append(next_token)\n",
    "        \n",
    "        # 종료 조건 (예: 마침표)\n",
    "        if next_token == stoi['.']:\n",
    "            break\n",
    "    \n",
    "    return context\n",
    "\n",
    "# 다양한 설정으로 생성\n",
    "settings = [\n",
    "    {\"name\": \"Greedy\", \"temp\": 0.01, \"top_k\": 1},\n",
    "    {\"name\": \"Conservative\", \"temp\": 0.7, \"top_k\": 5},\n",
    "    {\"name\": \"Balanced\", \"temp\": 1.0, \"top_p\": 0.9},\n",
    "    {\"name\": \"Creative\", \"temp\": 1.3, \"top_p\": 0.95},\n",
    "]\n",
    "\n",
    "print(\"다양한 생성 전략:\\n\")\n",
    "for setting in settings:\n",
    "    print(f\"{setting['name']:15}:\", end=\" \")\n",
    "    \n",
    "    tokens = generate(\n",
    "        [stoi['The']], \n",
    "        max_new_tokens=6,\n",
    "        temperature=setting.get('temp', 1.0),\n",
    "        top_k=setting.get('top_k'),\n",
    "        top_p=setting.get('top_p')\n",
    "    )\n",
    "    \n",
    "    text = ' '.join([itos[t] for t in tokens])\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Repetition Penalty\n",
    "\n",
    "반복을 줄이기 위한 페널티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_repetition_penalty(logits, generated_tokens, penalty=1.2):\n",
    "    \"\"\"이미 생성된 토큰에 페널티 적용\"\"\"\n",
    "    for token in set(generated_tokens):\n",
    "        # 이미 나온 토큰의 logit을 감소\n",
    "        logits[token] = logits[token] / penalty\n",
    "    return logits\n",
    "\n",
    "# 반복 페널티 효과 시연\n",
    "context = [stoi['The'], stoi['cat'], stoi['sat']]\n",
    "logits = torch.tensor([1.0] * vocab_size)  # 균등한 logits\n",
    "\n",
    "# 페널티 없음\n",
    "probs_no_penalty = F.softmax(logits, dim=-1)\n",
    "\n",
    "# 페널티 적용\n",
    "logits_with_penalty = apply_repetition_penalty(logits.clone(), context, penalty=2.0)\n",
    "probs_with_penalty = F.softmax(logits_with_penalty, dim=-1)\n",
    "\n",
    "# 비교 시각화\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.bar(range(vocab_size), probs_no_penalty.numpy())\n",
    "ax1.set_title('Without Repetition Penalty')\n",
    "ax1.set_xlabel('Token')\n",
    "ax1.set_xticks(range(vocab_size))\n",
    "ax1.set_xticklabels(vocab, rotation=45)\n",
    "\n",
    "ax2.bar(range(vocab_size), probs_with_penalty.numpy())\n",
    "ax2.set_title('With Repetition Penalty (penalty=2.0)')\n",
    "ax2.set_xlabel('Token')\n",
    "ax2.set_xticks(range(vocab_size))\n",
    "ax2.set_xticklabels(vocab, rotation=45)\n",
    "\n",
    "# 이미 나온 토큰 표시\n",
    "for idx in context:\n",
    "    ax2.bar(idx, probs_with_penalty[idx].numpy(), color='red', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"빨간색 막대 = 이미 생성된 토큰 (페널티 적용)\")\n",
    "print(\"→ 반복 확률 감소\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 핵심 인사이트\n",
    "\n",
    "1. **Autoregressive = 순차적 생성**\n",
    "   - 한 번에 한 토큰\n",
    "   - 이전 출력이 다음 입력\n",
    "\n",
    "2. **Temperature = 창의성 조절**\n",
    "   - Low: 안전하고 예측 가능\n",
    "   - High: 창의적이고 다양함\n",
    "\n",
    "3. **Top-k/Top-p = 품질 보장**\n",
    "   - 낮은 확률 토큰 제거\n",
    "   - 무의미한 출력 방지\n",
    "\n",
    "4. **Trade-offs**\n",
    "   - Quality vs Diversity\n",
    "   - Safety vs Creativity\n",
    "   - Speed vs Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 실전 팁\n",
    "\n",
    "### 용도별 추천 설정\n",
    "\n",
    "**코드 생성**\n",
    "```python\n",
    "temperature=0.2, top_k=10\n",
    "# 정확성 중요, 창의성 불필요\n",
    "```\n",
    "\n",
    "**창작 글쓰기**\n",
    "```python\n",
    "temperature=1.0, top_p=0.9\n",
    "# 다양성과 창의성 중요\n",
    "```\n",
    "\n",
    "**대화/챗봇**\n",
    "```python\n",
    "temperature=0.7, top_k=40\n",
    "# 균형잡힌 응답\n",
    "```\n",
    "\n",
    "**요약/번역**\n",
    "```python\n",
    "temperature=0.3, top_k=5\n",
    "# 정확성과 일관성 중요\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}