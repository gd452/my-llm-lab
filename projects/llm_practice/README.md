# LLM ì‹¤ìŠµ í”„ë¡œì íŠ¸

ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ LLM í™œìš© ê¸°ë²•ì„ ë°°ì›Œë´…ë‹ˆë‹¤.

## ğŸŒŸ í•˜ì´ë¼ì´íŠ¸

- **Qwen3 ìµœì‹  ëª¨ë¸** í™œìš© (2025ë…„ 4ì›” ì¶œì‹œ)
- **Thinking Mode** ì§€ì›ìœ¼ë¡œ ì‹¬ì¸µ ì¶”ë¡  ê°€ëŠ¥
- **ì‹¤ë¬´ ì¤‘ì‹¬** ì½”ë“œì™€ ì˜ˆì œ
- **ë‹¨ê³„ë³„** í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼

## í•™ìŠµ ëª©í‘œ

1. **Ollama + Qwen3** ë¡œì»¬ LLM ì„¤ì • ë° í™œìš©
2. **LangChain** í”„ë ˆì„ì›Œí¬ë¡œ ì²´ì¸ êµ¬ì„±
3. **Embeddings** ë²¡í„°í™”ì™€ ìœ ì‚¬ë„ ê²€ìƒ‰
4. **RAG** ê¸°ë°˜ ì§€ì‹ í™œìš© ì‹œìŠ¤í…œ
5. **Fine-tuning** LoRAë¡œ íš¨ìœ¨ì  ì»¤ìŠ¤í„°ë§ˆì´ì§•
6. **Agents** ReAct í”„ë ˆì„ì›Œí¬ ììœ¨ ì—ì´ì „íŠ¸

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm_practice/
â”œâ”€â”€ 01_ollama/          # Ollama + Qwen3 ê¸°ì´ˆ
â”‚   â”œâ”€â”€ setup.md       # Qwen3 ì„¤ì¹˜ ê°€ì´ë“œ
â”‚   â””â”€â”€ basic_chat.py  # ê¸°ë³¸ ëŒ€í™” êµ¬í˜„
â”‚
â”œâ”€â”€ 02_langchain/       # LangChain í™œìš©
â”‚   â”œâ”€â”€ basic_setup.py       # ê¸°ë³¸ ì²´ì¸ êµ¬ì„±
â”‚   â””â”€â”€ prompt_templates.py  # í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
â”‚
â”œâ”€â”€ 03_embeddings/      # ì„ë² ë”©ê³¼ ë²¡í„° ê²€ìƒ‰
â”‚   â””â”€â”€ embedding_basics.py  # ì„ë² ë”© ê¸°ì´ˆ
â”‚
â”œâ”€â”€ 04_rag_basics/      # RAG ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ simple_rag.py        # RAG íŒŒì´í”„ë¼ì¸
â”‚
â”œâ”€â”€ 05_fine_tuning/     # íŒŒì¸íŠœë‹
â”‚   â””â”€â”€ lora_finetuning.py   # LoRA íŒŒì¸íŠœë‹
â”‚
â””â”€â”€ 06_agents/          # AI ì—ì´ì „íŠ¸
    â””â”€â”€ autonomous_agents.py  # ReAct ì—ì´ì „íŠ¸
```

## ì»¤ë¦¬í˜ëŸ¼

### ğŸ“… Week 1: ê¸°ì´ˆ ì„¸íŒ…
- [x] Ollama ì„¤ì¹˜ ë° Qwen3 ëª¨ë¸ ì„¤ì •
- [x] Thinking Modeë¥¼ í™œìš©í•œ ì‹¬ì¸µ ì¶”ë¡ 
- [x] ê¸°ë³¸ API í˜¸ì¶œ ë° ëŒ€í™” êµ¬í˜„

### ğŸ”— Week 2: í”„ë ˆì„ì›Œí¬ í™œìš©
- [x] LangChain ê¸°ë³¸ ì²´ì¸ êµ¬ì„±
- [x] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ Few-shot Learning
- [x] ì„ë² ë”©ê³¼ ì˜ë¯¸ ê²€ìƒ‰

### ğŸ¯ Week 3: RAG & íŒŒì¸íŠœë‹
- [x] ë²¡í„° DBì™€ ë¬¸ì„œ ê²€ìƒ‰
- [x] RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- [x] LoRAë¡œ íš¨ìœ¨ì  íŒŒì¸íŠœë‹

### ğŸ¤– Week 4: ì—ì´ì „íŠ¸ ê°œë°œ
- [x] ReAct í”„ë ˆì„ì›Œí¬ êµ¬í˜„
- [x] ë„êµ¬ ì‚¬ìš©ê³¼ ë©”ëª¨ë¦¬ ê´€ë¦¬
- [x] ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ

## ì„¤ì¹˜ ê°€ì´ë“œ

### 1ï¸âƒ£ ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€
pip install langchain langchain-community
pip install sentence-transformers
pip install chromadb
pip install peft transformers
```

### 2ï¸âƒ£ Ollama ì„¤ì¹˜
```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows (WSL2 ê¶Œì¥)
```

### 3ï¸âƒ£ Qwen3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# Qwen3 ìµœì‹  ëª¨ë¸ (Thinking Mode ì§€ì›)
ollama pull qwen3:8b
ollama pull qwen3:30b-a3b  # MoE ëª¨ë¸ (ì„ íƒ)

# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
ollama run qwen3:8b
```

## ë¹ ë¥¸ ì‹œì‘

### ê¸°ë³¸ ëŒ€í™”
```python
# 01_ollama/basic_chat.py
from QwenChat import QwenChat

chat = QwenChat(model="qwen3:8b")
response = chat.chat("What is machine learning?")
print(response)
```

### Thinking Mode í™œìš©
```python
# Qwen3ì˜ íŠ¹ë³„ ê¸°ëŠ¥
response = chat.chat(
    "í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì˜ 10ë²ˆì§¸ í•­ì„ êµ¬í•´ì£¼ì„¸ìš”",
    thinking_mode=True  # ì‹¬ì¸µ ì¶”ë¡  í™œì„±í™”
)
```

## í•™ìŠµ ìë£Œ

- [ğŸ“– Qwen3 ê³µì‹ ë¬¸ì„œ](https://qwenlm.github.io/blog/qwen3/)
- [ğŸ¦™ Ollama ê³µì‹ ì‚¬ì´íŠ¸](https://ollama.ai/)
- [ğŸ”— LangChain íŠœí† ë¦¬ì–¼](https://python.langchain.com/)
- [ğŸ† LoRA ë…¼ë¬¸](https://arxiv.org/abs/2106.09685)
- [ğŸ¤” ReAct í”„ë ˆì„ì›Œí¬](https://arxiv.org/abs/2210.03629)

## ì‹¤ìŠµ í™˜ê²½

- **OS**: macOS/Linux/Windows (WSL2)
- **Python**: 3.9+
- **GPU**: ì„ íƒì‚¬í•­ (CPUë¡œë„ ê°€ëŠ¥)
- **RAM**: 8GB+ ê¶Œì¥ (16GB ì¶”ì²œ)
- **ì €ì¥ê³µê°„**: 10GB+ (ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ìƒì´)

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Ollama ì—°ê²° ì˜¤ë¥˜
```bash
# Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve

# ë˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
ollama serve &
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
ollama pull qwen3:4b

# ë˜ëŠ” ì–‘ìí™” ëª¨ë¸
ollama pull qwen3:8b-q4_0
```

## ê¸°ì—¬

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ê°œì„  ì‚¬í•­ì´ ìˆìœ¼ë©´ Issuesì— ë“±ë¡í•´ì£¼ì„¸ìš”.

## ë¼ì´ì„ ìŠ¤

MIT License