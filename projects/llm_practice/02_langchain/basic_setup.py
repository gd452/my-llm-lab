"""
LangChain + Ollama ê¸°ë³¸ ì…‹ì—…
ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” íŒ¨í„´ë“¤
"""

from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.chains import LLMChain, SimpleSequentialChain
from langchain.schema import BaseOutputParser
import json
from typing import Dict, List, Any

class BasicLangChainSetup:
    """LangChain ê¸°ë³¸ ì…‹ì—… í´ë˜ìŠ¤"""
    
    def __init__(self, model: str = "qwen3:8b"):
        self.llm = Ollama(
            model=model,
            temperature=0.7,
            num_predict=256,  # ìµœëŒ€ í† í° ìˆ˜
        )
        
    def simple_chain(self, topic: str) -> str:
        """ê°€ì¥ ê¸°ë³¸ì ì¸ ì²´ì¸"""
        prompt = PromptTemplate(
            input_variables=["topic"],
            template="Explain {topic} in 3 bullet points:"
        )
        
        chain = LLMChain(llm=self.llm, prompt=prompt)
        return chain.run(topic=topic)
    
    def chat_prompt_chain(self, user_input: str) -> str:
        """ChatPromptTemplate ì‚¬ìš© (ë” êµ¬ì¡°í™”ëœ ë°©ì‹)"""
        chat_prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful AI assistant specialized in technology."),
            ("human", "{user_input}"),
        ])
        
        chain = LLMChain(llm=self.llm, prompt=chat_prompt)
        return chain.run(user_input=user_input)
    
    def sequential_chain(self, topic: str) -> Dict[str, str]:
        """ìˆœì°¨ì  ì²´ì¸ - ì—¬ëŸ¬ ë‹¨ê³„ ì²˜ë¦¬"""
        
        # ì²« ë²ˆì§¸ ì²´ì¸: ê°œë… ì„¤ëª…
        explain_prompt = PromptTemplate(
            input_variables=["topic"],
            template="Explain {topic} in simple terms:"
        )
        explain_chain = LLMChain(llm=self.llm, prompt=explain_prompt)
        
        # ë‘ ë²ˆì§¸ ì²´ì¸: ì‹¤ì œ ì˜ˆì‹œ ìƒì„±
        example_prompt = PromptTemplate(
            input_variables=["explanation"],
            template="Based on this explanation: {explanation}\n\nProvide a real-world example:"
        )
        example_chain = LLMChain(llm=self.llm, prompt=example_prompt)
        
        # ì²´ì¸ ì—°ê²°
        overall_chain = SimpleSequentialChain(
            chains=[explain_chain, example_chain],
            verbose=True
        )
        
        result = overall_chain.run(topic)
        
        return {
            "topic": topic,
            "final_output": result
        }
    
    def custom_output_parser(self, question: str):
        """ì»¤ìŠ¤í…€ ì¶œë ¥ íŒŒì„œ ì‚¬ìš©"""
        
        class BulletPointParser(BaseOutputParser):
            def parse(self, text: str) -> List[str]:
                """í…ìŠ¤íŠ¸ë¥¼ bullet point ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±"""
                lines = text.strip().split('\n')
                bullet_points = []
                for line in lines:
                    line = line.strip()
                    if line and (line.startswith('â€¢') or 
                                line.startswith('-') or 
                                line.startswith('*') or
                                line[0].isdigit()):
                        # ë¶ˆë¦¿ í¬ì¸íŠ¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                        clean_line = line.lstrip('â€¢-*1234567890. ')
                        if clean_line:
                            bullet_points.append(clean_line)
                return bullet_points
        
        prompt = PromptTemplate(
            input_variables=["question"],
            template="Answer this question with 3 bullet points:\n{question}"
        )
        
        chain = LLMChain(
            llm=self.llm, 
            prompt=prompt,
            output_parser=BulletPointParser()
        )
        
        return chain.run(question=question)
    
    def json_output_chain(self, product: str) -> Dict:
        """JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥"""
        
        prompt = PromptTemplate(
            input_variables=["product"],
            template="""
Generate a product description in JSON format for: {product}

The JSON should have these fields:
- name: product name
- category: product category
- features: list of 3 key features
- price_range: estimated price range
- target_audience: who would buy this

Output only valid JSON, no additional text:
"""
        )
        
        chain = LLMChain(llm=self.llm, prompt=prompt)
        result = chain.run(product=product)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ì²˜ë¦¬)
            if '```json' in result:
                result = result.split('```json')[1].split('```')[0]
            elif '```' in result:
                result = result.split('```')[1].split('```')[0]
            
            return json.loads(result.strip())
        except json.JSONDecodeError:
            return {"error": "Failed to parse JSON", "raw": result}
    
    def conditional_chain(self, text: str, task: str) -> str:
        """ì¡°ê±´ë¶€ ì²´ì¸ - taskì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬"""
        
        task_prompts = {
            "summarize": "Summarize this text in 2 sentences: {text}",
            "translate": "Translate this to Korean: {text}",
            "analyze": "Analyze the sentiment and key points: {text}",
            "improve": "Rewrite this text to be more professional: {text}"
        }
        
        if task not in task_prompts:
            return f"Unknown task: {task}. Available: {list(task_prompts.keys())}"
        
        prompt = PromptTemplate(
            input_variables=["text"],
            template=task_prompts[task]
        )
        
        chain = LLMChain(llm=self.llm, prompt=prompt)
        return chain.run(text=text)
    
    def batch_processing(self, items: List[str], task_template: str) -> List[str]:
        """ë°°ì¹˜ ì²˜ë¦¬ - ì—¬ëŸ¬ ì•„ì´í…œ í•œë²ˆì— ì²˜ë¦¬"""
        
        prompt = PromptTemplate(
            input_variables=["item"],
            template=task_template
        )
        
        chain = LLMChain(llm=self.llm, prompt=prompt)
        
        results = []
        for item in items:
            result = chain.run(item=item)
            results.append(result)
            print(f"Processed: {item[:30]}...")
        
        return results

def demo_basic_chains():
    """ê¸°ë³¸ ì²´ì¸ ë°ëª¨"""
    
    print("ğŸ”— LangChain ê¸°ë³¸ ì²´ì¸ ë°ëª¨")
    print("=" * 60)
    
    setup = BasicLangChainSetup()
    
    # 1. ê°„ë‹¨í•œ ì²´ì¸
    print("\n1. Simple Chain:")
    result = setup.simple_chain("machine learning")
    print(result)
    
    # 2. Chat í”„ë¡¬í”„íŠ¸
    print("\n2. Chat Prompt Chain:")
    result = setup.chat_prompt_chain("What are the benefits of using Docker?")
    print(result)
    
    # 3. ìˆœì°¨ ì²´ì¸
    print("\n3. Sequential Chain:")
    result = setup.sequential_chain("blockchain")
    print(f"Final output: {result['final_output'][:200]}...")
    
    # 4. JSON ì¶œë ¥
    print("\n4. JSON Output:")
    result = setup.json_output_chain("wireless earbuds")
    if isinstance(result, dict) and 'error' not in result:
        print(json.dumps(result, indent=2))
    else:
        print(result)

def demo_advanced_features():
    """ê³ ê¸‰ ê¸°ëŠ¥ ë°ëª¨"""
    
    print("\nğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ë°ëª¨")
    print("=" * 60)
    
    setup = BasicLangChainSetup()
    
    # 1. ì»¤ìŠ¤í…€ íŒŒì„œ
    print("\n1. Custom Output Parser:")
    result = setup.custom_output_parser("What are the benefits of cloud computing?")
    for i, point in enumerate(result, 1):
        print(f"  {i}. {point}")
    
    # 2. ì¡°ê±´ë¶€ ì²˜ë¦¬
    print("\n2. Conditional Chain:")
    text = "Artificial intelligence is transforming industries worldwide."
    
    tasks = ["summarize", "translate", "analyze"]
    for task in tasks:
        print(f"\n  Task: {task}")
        result = setup.conditional_chain(text, task)
        print(f"  Result: {result[:150]}...")
    
    # 3. ë°°ì¹˜ ì²˜ë¦¬
    print("\n3. Batch Processing:")
    items = [
        "Python programming",
        "Data science",
        "Cloud computing"
    ]
    template = "Write a one-line definition for: {item}"
    results = setup.batch_processing(items, template)
    for item, result in zip(items, results):
        print(f"\n  {item}:")
        print(f"  â†’ {result}")

def demo_error_handling():
    """ì—ëŸ¬ ì²˜ë¦¬ ë°ëª¨"""
    
    print("\nâš ï¸ ì—ëŸ¬ ì²˜ë¦¬ ë°ëª¨")
    print("=" * 60)
    
    setup = BasicLangChainSetup()
    
    # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        result = setup.simple_chain("test")
        print("âœ… Ollama ì—°ê²° ì„±ê³µ")
    except Exception as e:
        print(f"âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {e}")
        print("í•´ê²°ë°©ë²•:")
        print("1. ollama serve ì‹¤í–‰ í™•ì¸")
        print("2. ollama pull qwen3:8b ì‹¤í–‰")
        print("3. http://localhost:11434 ì ‘ì† í…ŒìŠ¤íŠ¸")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        mode = sys.argv[1]
        if mode == "advanced":
            demo_advanced_features()
        elif mode == "error":
            demo_error_handling()
        else:
            print("Usage: python basic_setup.py [advanced|error]")
    else:
        # ê¸°ë³¸ ë°ëª¨
        demo_basic_chains()
        
        print("\n" + "=" * 60)
        print("ğŸ’¡ ë‹¤ë¥¸ ë°ëª¨:")
        print("  python basic_setup.py advanced  # ê³ ê¸‰ ê¸°ëŠ¥")
        print("  python basic_setup.py error     # ì—ëŸ¬ ì²˜ë¦¬")