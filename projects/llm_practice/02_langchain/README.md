# LangChain + Ollama í†µí•©

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- LangChain ê¸°ë³¸ ê°œë… ì´í•´
- Ollamaì™€ LangChain í†µí•©
- ì²´ì¸(Chain) êµ¬ì„±ê³¼ í™œìš©
- í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©
- ë©”ëª¨ë¦¬ ê´€ë¦¬

## ğŸ“š ì»¤ë¦¬í˜ëŸ¼

### 1. ê¸°ë³¸ ì…‹ì—… (`basic_setup.py`)
- LangChain ì„¤ì¹˜
- Ollama ì—°ë™
- ì²« ì²´ì¸ êµ¬ì„±

### 2. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (`prompt_templates.py`)
- PromptTemplate í™œìš©
- FewShotPromptTemplate
- ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±

### 3. ì²´ì¸ íŒ¨í„´ (`chain_patterns.py`)
- Sequential Chain
- Router Chain
- Transform Chain
- ì»¤ìŠ¤í…€ ì²´ì¸

### 4. ë©”ëª¨ë¦¬ ê´€ë¦¬ (`memory_management.py`)
- ConversationBufferMemory
- ConversationSummaryMemory
- VectorStoreMemory
- ë©”ëª¨ë¦¬ ì˜ì†í™”

### 5. ì¶œë ¥ íŒŒì„œ (`output_parsers.py`)
- JSON ì¶œë ¥ íŒŒì‹±
- Pydantic í†µí•©
- êµ¬ì¡°í™”ëœ ì¶œë ¥

## ğŸ“¦ í•„ìš” íŒ¨í‚¤ì§€

```bash
pip install langchain langchain-community pydantic
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

```python
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Ollama ëª¨ë¸ ì´ˆê¸°í™”
llm = Ollama(model="qwen3:8b")

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = PromptTemplate(
    input_variables=["topic"],
    template="Explain {topic} in simple terms:"
)

# ì²´ì¸ êµ¬ì„±
chain = LLMChain(llm=llm, prompt=prompt)

# ì‹¤í–‰
result = chain.run(topic="quantum computing")
print(result)
```

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] LangChain ì„¤ì¹˜
- [ ] ê¸°ë³¸ ì²´ì¸ êµ¬ì„±
- [ ] í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™œìš©
- [ ] ë©”ëª¨ë¦¬ êµ¬í˜„
- [ ] ì¶œë ¥ íŒŒì‹± êµ¬í˜„