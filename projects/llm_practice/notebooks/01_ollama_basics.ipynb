{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Ollama + Qwen3 기초\n",
    "\n",
    "## 🎯 학습 목표\n",
    "1. Ollama의 개념과 작동 원리 이해\n",
    "2. Qwen3 모델의 특징과 장점 파악\n",
    "3. 로컬 LLM 실행 및 활용법 습득\n",
    "4. Thinking Mode를 통한 심층 추론 활용\n",
    "\n",
    "## 📚 핵심 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ollama란?\n",
    "\n",
    "**Ollama**는 대규모 언어 모델(LLM)을 로컬에서 쉽게 실행할 수 있게 해주는 도구입니다.\n",
    "\n",
    "### 주요 특징:\n",
    "- 🖥️ **로컬 실행**: 인터넷 연결 없이 개인 컴퓨터에서 실행\n",
    "- 🔒 **프라이버시**: 데이터가 외부로 전송되지 않음\n",
    "- 💰 **무료**: API 비용 없이 무제한 사용\n",
    "- 🚀 **간편한 설정**: 한 줄 명령으로 모델 다운로드 및 실행\n",
    "\n",
    "### 작동 원리:\n",
    "```\n",
    "사용자 → Ollama CLI → 모델 다운로드 → 로컬 서버 실행 → REST API 제공\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Qwen3 모델 소개\n",
    "\n",
    "**Qwen3**는 Alibaba에서 2025년 4월에 출시한 최신 언어 모델입니다.\n",
    "\n",
    "### Qwen3 vs Qwen2 비교:\n",
    "\n",
    "| 특징 | Qwen2 | Qwen3 |\n",
    "|------|-------|-------|\n",
    "| 추론 능력 | 좋음 | 매우 뛰어남 (QwQ 수준) |\n",
    "| 모델 효율성 | 일반 | 뛰어남 (4B가 72B 성능) |\n",
    "| Thinking Mode | ❌ | ✅ /think, /no_think |\n",
    "| MoE 지원 | 제한적 | 완전 지원 |\n",
    "| 코딩 능력 | 좋음 | 매우 뛰어남 |\n",
    "\n",
    "### Thinking Mode란?\n",
    "- 복잡한 문제에 대해 단계별로 사고하는 모드\n",
    "- `/think`로 활성화, `/no_think`로 비활성화\n",
    "- Chain of Thought (CoT) 추론을 자동으로 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 설치 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama 설치 확인\n",
    "!ollama --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen3 모델 다운로드 (처음 한 번만)\n",
    "# 크기별 선택:\n",
    "# - qwen3:4b (작지만 강력)\n",
    "# - qwen3:8b (균형잡힌 선택) \n",
    "# - qwen3:30b-a3b (MoE, 고성능)\n",
    "\n",
    "!ollama pull qwen3:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치된 모델 확인\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def chat_with_qwen(prompt, model=\"qwen3:8b\", thinking_mode=False):\n",
    "    \"\"\"Qwen3와 대화하는 함수\"\"\"\n",
    "    \n",
    "    # Thinking Mode 적용\n",
    "    if thinking_mode:\n",
    "        prompt = f\"/think {prompt}\"\n",
    "    \n",
    "    # API 호출\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()['response']\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking for three strengths of Python. Let me start by recalling what I know about Python's advantages.\n",
      "\n",
      "First, Python is known for its simplicity and readability. The syntax is straightforward, which makes it easy for beginners to learn and for experienced developers to write code that's easy to maintain. That's a solid point.\n",
      "\n",
      "Second, Python has a vast standard library and a rich ecosystem of third-party packages. This means you can find libraries for almost any task, from web development to data analysis, which saves time and effort. For example, libraries like NumPy, Pandas, and Django are really popular.\n",
      "\n",
      "Third, Python is versatile and can be used across different domains. Whether it's web development, scientific computing, automation, or machine learning, Python has the tools and frameworks to handle it. This versatility makes it a go-to language for many developers.\n",
      "\n",
      "Wait, are there other strengths? Maybe things like dynamic typing or integration with other languages? But the user asked for three, so I should stick to the most commonly cited ones. Let me make sure the three points I mentioned are accurate and cover the main advantages. Also, I should explain each point clearly and concisely, maybe with examples to illustrate them. That should help the user understand why Python is popular.\n",
      "</think>\n",
      "\n",
      "파이썬의 주요 장점을 3가지 정리해드릴게요:\n",
      "\n",
      "### 1. **간결하고 가독성이 높은 문법**\n",
      "   - 파이썬은 `print(\"Hello\")`처럼 짧고 직관적인 문법으로 코드를 작성할 수 있어 **개발 생산성**을 높입니다.\n",
      "   - 들여쓰기(Indentation)로 코드 블록을 구분하므로 **공간 낭비 없이 구조화된 코드**를 작성할 수 있습니다.\n",
      "   - 예:  \n",
      "     ```python\n",
      "     def greet():\n",
      "         print(\"Hello, World!\")\n",
      "     ```\n",
      "\n",
      "### 2. **다양한 라이브러리와 생태계**\n",
      "   - **표준 라이브러리**와 **사용자 라이브러리**가 풍부해 데이터 분석(`pandas`, `numpy`), 머신러닝(`scikit-learn`, `tensorflow`), 웹 개발(`Django`, `Flask`) 등 다양한 분야에서 활용 가능합니다.\n",
      "   - 예:  \n",
      "     ```python\n",
      "     import pandas as pd\n",
      "     df = pd.read_csv(\"data.csv\")\n",
      "     ```\n",
      "\n",
      "### 3. **다중 분야에서의 유연성**\n",
      "   - **웹 개발**, **데이터 과학**, **AI/머신러닝**, **자동화**, **게임 개발** 등 다양한 분야에서 사용 가능합니다.\n",
      "   - **인터프리터 언어**로 **즉시 실행**이 가능해 실시간 테스트와 개발이 용이합니다.\n",
      "\n",
      "이러한 장점 덕분에 파이썬은 **초보자부터 전문가까지** 다양한 개발자들의 선호 언어로 자리 잡고 있습니다! 🐍\n"
     ]
    }
   ],
   "source": [
    "# 간단한 질문\n",
    "response = chat_with_qwen(\"파이썬의 장점을 3가지 알려주세요\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Thinking Mode 활용\n",
    "\n",
    "복잡한 추론이 필요한 문제에서 Thinking Mode를 활용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 모드 vs Thinking Mode 비교\n",
    "problem = \"농부가 강을 건너야 하는데, 늑대, 양, 양배추를 가지고 있습니다. 보트는 농부와 한 가지만 실을 수 있습니다. 늑대와 양을 혼자 두면 늑대가 양을 먹고, 양과 양배추를 혼자 두면 양이 양배추를 먹습니다. 어떻게 모두 안전하게 강을 건널 수 있을까요?\"\n",
    "\n",
    "print(\"=== 일반 모드 ===\")\n",
    "normal_response = chat_with_qwen(problem, thinking_mode=False)\n",
    "print(normal_response[:500] + \"...\\n\")\n",
    "\n",
    "print(\"=== Thinking Mode ===\")\n",
    "thinking_response = chat_with_qwen(problem, thinking_mode=True)\n",
    "print(thinking_response[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 스트리밍 응답\n",
    "\n",
    "실시간으로 응답을 받아보는 스트리밍 모드를 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chat(prompt, model=\"qwen3:8b\"):\n",
    "    \"\"\"스트리밍 방식으로 응답 받기\"\"\"\n",
    "    \n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/generate',\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": True\n",
    "        },\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            data = json.loads(line)\n",
    "            token = data.get('response', '')\n",
    "            print(token, end='', flush=True)\n",
    "            full_response += token\n",
    "            \n",
    "            if data.get('done', False):\n",
    "                break\n",
    "    \n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍으로 이야기 생성\n",
    "story = stream_chat(\"인공지능이 주인공인 짧은 SF 이야기를 만들어주세요 (100자 이내)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 실전 활용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QwenAssistant:\n",
    "    \"\"\"실무에서 사용할 수 있는 Qwen3 어시스턴트\"\"\"\n",
    "    \n",
    "    def __init__(self, model=\"qwen3:8b\"):\n",
    "        self.model = model\n",
    "        self.base_url = \"http://localhost:11434\"\n",
    "    \n",
    "    def code_review(self, code):\n",
    "        \"\"\"코드 리뷰\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        다음 코드를 리뷰해주세요:\n",
    "        \n",
    "        ```python\n",
    "        {code}\n",
    "        ```\n",
    "        \n",
    "        1. 잠재적 버그\n",
    "        2. 성능 개선점\n",
    "        3. 코드 스타일 제안\n",
    "        \"\"\"\n",
    "        return chat_with_qwen(prompt, self.model)\n",
    "    \n",
    "    def explain_error(self, error_message):\n",
    "        \"\"\"에러 메시지 설명\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        다음 에러를 설명하고 해결 방법을 알려주세요:\n",
    "        \n",
    "        {error_message}\n",
    "        \"\"\"\n",
    "        return chat_with_qwen(prompt, self.model)\n",
    "    \n",
    "    def generate_docstring(self, function_code):\n",
    "        \"\"\"함수 문서화 자동 생성\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        다음 함수에 대한 docstring을 작성해주세요:\n",
    "        \n",
    "        {function_code}\n",
    "        \n",
    "        Google 스타일 docstring으로 작성해주세요.\n",
    "        \"\"\"\n",
    "        return chat_with_qwen(prompt, self.model)\n",
    "    \n",
    "    def sql_from_text(self, description, schema=None):\n",
    "        \"\"\"자연어를 SQL로 변환\"\"\"\n",
    "        prompt = f\"자연어: {description}\\n\"\n",
    "        if schema:\n",
    "            prompt += f\"스키마: {schema}\\n\"\n",
    "        prompt += \"SQL 쿼리:\"\n",
    "        return chat_with_qwen(prompt, self.model, thinking_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어시스턴트 사용 예제\n",
    "assistant = QwenAssistant()\n",
    "\n",
    "# 1. 코드 리뷰\n",
    "sample_code = \"\"\"\n",
    "def calculate_average(numbers):\n",
    "    sum = 0\n",
    "    for i in range(len(numbers)):\n",
    "        sum = sum + numbers[i]\n",
    "    average = sum / len(numbers)\n",
    "    return average\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== 코드 리뷰 ===\")\n",
    "review = assistant.code_review(sample_code)\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SQL 생성\n",
    "print(\"\\n=== SQL 생성 ===\")\n",
    "sql = assistant.sql_from_text(\n",
    "    \"지난 달 매출이 100만원 이상인 고객들의 이름과 이메일을 찾아줘\",\n",
    "    schema=\"customers(id, name, email), orders(id, customer_id, amount, date)\"\n",
    ")\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 성능 최적화 팁\n",
    "\n",
    "### 메모리 관리\n",
    "```bash\n",
    "# GPU 메모리 제한\n",
    "export OLLAMA_MAX_LOADED_MODELS=1\n",
    "export OLLAMA_NUM_GPU=1\n",
    "\n",
    "# CPU 스레드 설정\n",
    "export OLLAMA_NUM_THREAD=8\n",
    "```\n",
    "\n",
    "### 모델 선택 가이드\n",
    "- **qwen3:4b**: 빠른 응답이 필요한 경우 (채팅봇, 실시간 처리)\n",
    "- **qwen3:8b**: 균형잡힌 선택 (일반적인 작업)\n",
    "- **qwen3:30b-a3b**: 복잡한 추론, 코드 생성 (MoE 아키텍처)\n",
    "\n",
    "### 프롬프트 최적화\n",
    "1. 명확하고 구체적인 지시\n",
    "2. 예제 제공 (Few-shot learning)\n",
    "3. 출력 형식 명시\n",
    "4. Thinking Mode는 복잡한 문제에만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 실습 과제\n",
    "\n",
    "1. **기본 과제**: 자신만의 프롬프트 3개를 작성하고 일반 모드와 Thinking Mode 비교\n",
    "2. **심화 과제**: QwenAssistant 클래스에 새로운 메서드 3개 추가\n",
    "3. **프로젝트**: 특정 도메인(예: 요리, 운동, 공부)에 특화된 어시스턴트 만들기\n",
    "\n",
    "## 📚 추가 학습 자료\n",
    "\n",
    "- [Ollama 공식 문서](https://github.com/ollama/ollama)\n",
    "- [Qwen3 논문](https://qwenlm.github.io/blog/qwen3/)\n",
    "- [Prompt Engineering Guide](https://www.promptingguide.ai/)\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "다음 노트북에서는 **LangChain**을 활용하여 더 복잡한 체인과 워크플로우를 구성하는 방법을 배워보겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
