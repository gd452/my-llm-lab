# RAGSystem VectorStore ìˆ˜ì • ì½”ë“œ

## ë¬¸ì œì 
- VectorStoreì˜ `add_documents` í•¨ìˆ˜ê°€ ë©”íƒ€ë°ì´í„°ë¥¼ ë°›ì§€ ì•ŠìŒ
- RAGSystemì—ì„œ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ í˜¸ì¶œí•˜ì—¬ ì—ëŸ¬ ë°œìƒ
- ChromaDB í˜¸í™˜ì„± ë¬¸ì œ

## í•´ê²° ë°©ë²•

### 1. VectorStore í´ë˜ìŠ¤ ìˆ˜ì •

```python
import chromadb
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Dict, Optional

class VectorStore:
    def __init__(self, collection_name="knowledge_base"):
        # ìƒˆë¡œìš´ ChromaDB í´ë¼ì´ì–¸íŠ¸ (í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
        self.client = chromadb.PersistentClient(path="./chroma_db")
        
        # ì„ë² ë”© ëª¨ë¸
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # ì»¬ë ‰ì…˜ ìƒì„±/ë¡œë“œ
        try:
            self.collection = self.client.get_collection(collection_name)
            print(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' ë¡œë“œë¨")
        except:
            self.collection = self.client.create_collection(collection_name)
            print(f"ìƒˆ ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„±ë¨")
    
    def add_documents(self, documents: List[str], metadatas: Optional[List[Dict]] = None):
        """ë¬¸ì„œ ì¶”ê°€ (ë©”íƒ€ë°ì´í„° ì§€ì›)"""
        embeddings = self.embedding_model.encode(documents)
        
        # ë©”íƒ€ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”
        if metadatas is None:
            metadatas = [{} for _ in documents]
        
        # ChromaDBì— ì¶”ê°€
        self.collection.add(
            embeddings=embeddings.tolist(),
            documents=documents,
            metadatas=metadatas,
            ids=[f"doc_{i}" for i in range(len(documents))]
        )
        print(f"{len(documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ë¨")
    
    def search(self, query: str, n_results: int = 5):
        """ìœ ì‚¬ë„ ê²€ìƒ‰"""
        query_embedding = self.embedding_model.encode([query])
        
        results = self.collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=n_results
        )
        return results
    
    def delete_collection(self):
        """ì»¬ë ‰ì…˜ ì‚­ì œ"""
        try:
            self.client.delete_collection(self.collection.name)
            print(f"ì»¬ë ‰ì…˜ '{self.collection.name}' ì‚­ì œë¨")
        except Exception as e:
            print(f"ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    def get_collection_info(self):
        """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
        count = self.collection.count()
        print(f"ì»¬ë ‰ì…˜ '{self.collection.name}'ì— {count}ê°œ ë¬¸ì„œê°€ ì €ì¥ë¨")
        return count
```

### 2. RAGSystem í´ë˜ìŠ¤ ìˆ˜ì •

```python
class RAGSystem:
    """ì™„ì „í•œ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, llm_model="qwen3:8b", embedding_model="all-MiniLM-L6-v2"):
        # LLM ì´ˆê¸°í™”
        self.llm = Ollama(model=llm_model)
        
        # ë²¡í„° ìŠ¤í† ì–´
        self.vector_store = VectorStore("rag_system")
        
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", " ", ""]
        )
    
    def add_document(self, text: str, source: str = "unknown"):
        """ë¬¸ì„œ ì¶”ê°€ (ìë™ ì²­í‚¹)"""
        # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        chunks = self.text_splitter.split_text(text)
        
        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadatas = [
            {
                "source": source,
                "chunk_id": i,
                "total_chunks": len(chunks)
            }
            for i in range(len(chunks))
        ]
        
        # ë²¡í„° DBì— ì¶”ê°€ (ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜)
        self.vector_store.add_documents(chunks, metadatas)
        return len(chunks)
    
    def query(self, question: str, top_k: int = 3, use_thinking: bool = False):
        """RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ"""
        
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_results = self.vector_store.search(question, n_results=top_k)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context_docs = search_results['documents'][0] if search_results['documents'] else []
        context = "\n\n".join(context_docs)
        
        # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if use_thinking:
            prompt = f"""
ë‹¹ì‹ ì€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ìœ„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. 
ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ê´€ë ¨ì´ ì—†ëŠ” ê²½ìš° "ì œê³µëœ ì •ë³´ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë§í•´ì£¼ì„¸ìš”.

ë‹µë³€:
"""
        else:
            prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

{context}

ì§ˆë¬¸: {question}

ë‹µë³€:
"""
        
        # 4. LLM í˜¸ì¶œ
        try:
            response = self.llm(prompt)
            answer = response.strip()
        except Exception as e:
            answer = f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        
        # 5. ê²°ê³¼ ë°˜í™˜
        return {
            "answer": answer,
            "sources": context_docs,
            "num_sources": len(context_docs),
            "question": question
        }
```

### 3. ì‚¬ìš© ì˜ˆì‹œ

```python
# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
rag = RAGSystem()

# ë¬¸ì„œ ì¶”ê°€
documents = [
    """
    íšŒì‚¬ ê·œì • ë¬¸ì„œ
    
    1. ê·¼ë¬´ ì‹œê°„: ì˜¤ì „ 9ì‹œ - ì˜¤í›„ 6ì‹œ (ì ì‹¬ì‹œê°„ 12ì‹œ-1ì‹œ)
    2. ì¬íƒê·¼ë¬´: ì£¼ 2íšŒ ê°€ëŠ¥ (ì›”/ê¸ˆ ê¶Œì¥)
    3. íœ´ê°€: ì—°ì°¨ 15ì¼, ë³‘ê°€ 10ì¼
    4. êµìœ¡ ì§€ì›: ì—°ê°„ 200ë§Œì› í•œë„
    5. íšŒì˜: ë§¤ì£¼ ì›”ìš”ì¼ 10ì‹œ íŒ€ ë¯¸íŒ…
    """,
    
    """
    í”„ë¡œì íŠ¸ ê°€ì´ë“œë¼ì¸
    
    1. ì½”ë“œ ë¦¬ë·°: ëª¨ë“  PRì€ 2ëª… ì´ìƒì˜ ë¦¬ë·° í•„ìš”
    2. í…ŒìŠ¤íŠ¸: ì½”ë“œ ì»¤ë²„ë¦¬ì§€ 80% ì´ìƒ ìœ ì§€
    3. ë¬¸ì„œí™”: ëª¨ë“  ê³µê°œ APIëŠ” ë¬¸ì„œí™” í•„ìˆ˜
    4. ë¸Œëœì¹˜: feature/*, bugfix/*, hotfix/* ê·œì¹™ ì¤€ìˆ˜
    5. ë°°í¬: ë§¤ì£¼ í™”ìš”ì¼, ëª©ìš”ì¼ ì •ê¸° ë°°í¬
    """
]

sources = ["íšŒì‚¬ê·œì •", "í”„ë¡œì íŠ¸ê°€ì´ë“œ"]

# ë¬¸ì„œ ì¶”ê°€
for i, doc in enumerate(documents):
    chunks = rag.add_document(doc, source=sources[i])
    print(f"ë¬¸ì„œ {i+1}: {chunks}ê°œ ì²­í¬ë¡œ ë¶„í• ")

# ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
questions = [
    "ì¬íƒê·¼ë¬´ëŠ” ì–¸ì œ ê°€ëŠ¥í•œê°€ìš”?",
    "ì½”ë“œ ë¦¬ë·° ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì ì‹¬ì‹œê°„ì€ ì–¸ì œì¸ê°€ìš”?"
]

for question in questions:
    print(f"\n{'='*60}")
    print(f"â“ ì§ˆë¬¸: {question}")
    
    result = rag.query(question)
    
    print(f"\nğŸ’¡ ë‹µë³€: {result['answer']}")
    print(f"\nğŸ“š ì°¸ê³ í•œ ì†ŒìŠ¤ ({result['num_sources']}ê°œ):")
    for i, source in enumerate(result['sources'][:2]):
        print(f"  [{i+1}] {source[:100]}...")
```

## ì£¼ìš” ë³€ê²½ì‚¬í•­

1. **VectorStore.add_documents()**: ë©”íƒ€ë°ì´í„° ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
2. **ChromaDB í´ë¼ì´ì–¸íŠ¸**: `PersistentClient` ì‚¬ìš©ìœ¼ë¡œ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
3. **RAGSystem.add_document()**: ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ VectorStore í˜¸ì¶œ
4. **ì—ëŸ¬ ì²˜ë¦¬**: ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”

## í…ŒìŠ¤íŠ¸ ë°©ë²•

1. ìœ„ì˜ VectorStore í´ë˜ìŠ¤ë¥¼ ë…¸íŠ¸ë¶ì— ë³µì‚¬
2. RAGSystem í´ë˜ìŠ¤ë¥¼ ë…¸íŠ¸ë¶ì— ë³µì‚¬
3. ì‚¬ìš© ì˜ˆì‹œ ì½”ë“œ ì‹¤í–‰
4. ì—ëŸ¬ ì—†ì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
