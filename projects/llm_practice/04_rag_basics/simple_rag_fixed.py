"""
RAG (Retrieval-Augmented Generation) ê¸°ì´ˆ - Metadata ê°•í™” ë²„ì „
ë²¡í„° DB + LLMì„ í™œìš©í•œ ì§€ì‹ ê¸°ë°˜ ì‘ë‹µ ì‹œìŠ¤í…œ
"""

import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import chromadb
import requests
import json
import os
from datetime import datetime

class EnhancedRAG:
    """Metadataë¥¼ í™œìš©í•œ í–¥ìƒëœ RAG êµ¬í˜„"""
    
    def __init__(self, 
                 embedding_model: str = 'all-MiniLM-L6-v2',
                 llm_model: str = 'qwen3:8b',
                 collection_name: str = 'knowledge_base'):
        
        # ì„ë² ë”© ëª¨ë¸
        self.embedder = SentenceTransformer(embedding_model)
        
        # ChromaDB ì´ˆê¸°í™” (ë¡œì»¬ ë²¡í„° DB)
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        
        # ì»¬ë ‰ì…˜ ìƒì„±/ë¡œë“œ
        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (í…ŒìŠ¤íŠ¸ìš©)
            self.chroma_client.delete_collection(collection_name)
        except:
            pass
        
        self.collection = self.chroma_client.create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
        
        self.llm_model = llm_model
        self.llm_base_url = "http://localhost:11434"
    
    def add_documents(self, 
                      documents: List[str], 
                      metadatas: Optional[List[Dict]] = None,
                      auto_metadata: bool = True):
        """
        ë¬¸ì„œë¥¼ ë²¡í„° DBì— ì¶”ê°€ (í–¥ìƒëœ ë©”íƒ€ë°ì´í„° ì²˜ë¦¬)
        
        Args:
            documents: ì €ì¥í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            metadatas: ê° ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°
            auto_metadata: ìë™ ë©”íƒ€ë°ì´í„° ìƒì„± ì—¬ë¶€
        """
        
        # ì„ë² ë”© ìƒì„±
        embeddings = self.embedder.encode(documents).tolist()
        
        # ë©”íƒ€ë°ì´í„° ì²˜ë¦¬
        if metadatas is None:
            metadatas = []
        
        # ë©”íƒ€ë°ì´í„° ë³´ê°•
        enhanced_metadatas = []
        for i, doc in enumerate(documents):
            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
            base_metadata = metadatas[i] if i < len(metadatas) else {}
            
            # ìë™ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            if auto_metadata:
                enhanced_metadata = {
                    **base_metadata,  # ì›ë³¸ ë©”íƒ€ë°ì´í„° ìœ ì§€
                    "doc_id": f"doc_{i}_{hash(doc) % 100000}",
                    "char_length": len(doc),
                    "word_count": len(doc.split()),
                    "added_at": datetime.now().isoformat(),
                    "embedding_model": "all-MiniLM-L6-v2"
                }
                
                # ë¬¸ì„œ íƒ€ì… ìë™ ê°ì§€
                if "ì½”ë“œ" in doc or "def " in doc or "class " in doc:
                    enhanced_metadata["doc_type"] = "code"
                elif "?" in doc:
                    enhanced_metadata["doc_type"] = "question"
                else:
                    enhanced_metadata["doc_type"] = "text"
                    
            else:
                # auto_metadataê°€ Falseì¼ ë•Œë„ ìµœì†Œí•œì˜ ë©”íƒ€ë°ì´í„°ëŠ” í•„ìš”
                enhanced_metadata = base_metadata if base_metadata else {"doc_id": f"doc_{i}"}
            
            # ChromaDBëŠ” ë¬¸ìì—´, ìˆ«ì, ë¶ˆë¦°ë§Œ ì§€ì›
            # ë³µì¡í•œ íƒ€ì…ì€ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            clean_metadata = {}
            for key, value in enhanced_metadata.items():
                if isinstance(value, (str, int, float, bool)):
                    clean_metadata[key] = value
                elif value is None:
                    clean_metadata[key] = "null"
                else:
                    clean_metadata[key] = str(value)
            
            enhanced_metadatas.append(clean_metadata)
        
        # ID ìƒì„± (ìœ ë‹ˆí¬í•˜ê²Œ)
        ids = [meta.get("doc_id", f"doc_{i}") for i, meta in enumerate(enhanced_metadatas)]
        
        # ChromaDBì— ì €ì¥
        self.collection.add(
            embeddings=embeddings,
            documents=documents,
            metadatas=enhanced_metadatas,
            ids=ids
        )
        
        print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ (ë©”íƒ€ë°ì´í„° í¬í•¨)")
        return enhanced_metadatas
    
    def retrieve(self, 
                query: str, 
                top_k: int = 3,
                filter_metadata: Optional[Dict] = None) -> List[Dict]:
        """
        ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì§€ì›)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            filter_metadata: ë©”íƒ€ë°ì´í„° í•„í„° ì¡°ê±´
        """
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.embedder.encode(query).tolist()
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        query_params = {
            "query_embeddings": [query_embedding],
            "n_results": top_k
        }
        
        # ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©
        if filter_metadata:
            query_params["where"] = filter_metadata
        
        # ê²€ìƒ‰
        results = self.collection.query(**query_params)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        retrieved_docs = []
        if results['documents'] and len(results['documents'][0]) > 0:
            for i in range(len(results['documents'][0])):
                doc_info = {
                    'document': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i] if results['metadatas'] else {},
                    'distance': results['distances'][0][i] if results['distances'] else 0,
                    'relevance_score': 1.0 - (results['distances'][0][i] if results['distances'] else 0)
                }
                retrieved_docs.append(doc_info)
        
        return retrieved_docs
    
    def generate_response(self, query: str, context: str, metadata_context: str = "") -> str:
        """ì»¨í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•œ ì‘ë‹µ ìƒì„±"""
        
        # ë©”íƒ€ë°ì´í„° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        metadata_info = f"\nSource Information:\n{metadata_context}\n" if metadata_context else ""
        
        prompt = f"""You are a helpful assistant. Use the following context to answer the question.
If you cannot answer based on the context, say so.
{metadata_info}
Context:
{context}

Question: {query}

Answer:"""
        
        # Ollama API í˜¸ì¶œ
        try:
            response = requests.post(
                f"{self.llm_base_url}/api/generate",
                json={
                    "model": self.llm_model,
                    "prompt": prompt,
                    "stream": False,
                    "temperature": 0.7
                }
            )
            
            if response.status_code == 200:
                return response.json()['response']
            else:
                return f"Error: LLM API returned {response.status_code}"
        except Exception as e:
            return f"Error calling LLM: {str(e)}"
    
    def query(self, 
             question: str, 
             top_k: int = 3,
             use_metadata: bool = True,
             filter_metadata: Optional[Dict] = None) -> Dict[str, Any]:
        """
        í–¥ìƒëœ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            question: ì§ˆë¬¸
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            use_metadata: ë©”íƒ€ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
            filter_metadata: ë©”íƒ€ë°ì´í„° í•„í„°
        """
        
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = self.retrieve(question, top_k=top_k, filter_metadata=filter_metadata)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = "\n\n".join([doc['document'] for doc in retrieved_docs])
        
        # 3. ë©”íƒ€ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        metadata_context = ""
        if use_metadata and retrieved_docs:
            metadata_info = []
            for i, doc in enumerate(retrieved_docs, 1):
                meta = doc.get('metadata', {})
                source_info = f"Source {i}: "
                if meta.get('source'):
                    source_info += f"from {meta['source']}"
                if meta.get('added_at'):
                    source_info += f" (added: {meta['added_at'][:10]})"
                if meta.get('topic'):
                    source_info += f" [Topic: {meta['topic']}]"
                metadata_info.append(source_info)
            metadata_context = "\n".join(metadata_info)
        
        # 4. ì‘ë‹µ ìƒì„±
        answer = self.generate_response(question, context, metadata_context)
        
        return {
            'question': question,
            'answer': answer,
            'sources': retrieved_docs,
            'context_used': context,
            'metadata_used': metadata_context,
            'num_sources': len(retrieved_docs)
        }

class MetadataExamples:
    """ë©”íƒ€ë°ì´í„° í™œìš© ì˜ˆì œ"""
    
    @staticmethod
    def demonstrate_metadata_importance():
        """ë©”íƒ€ë°ì´í„°ì˜ ì¤‘ìš”ì„± ì‹œì—°"""
        
        print("\n" + "="*60)
        print("ğŸ“Š ë©”íƒ€ë°ì´í„°ê°€ RAG ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ ì´ìœ ")
        print("="*60)
        
        rag = EnhancedRAG()
        
        # 1. ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ë¬¸ì„œ ì¶”ê°€ (ë©”íƒ€ë°ì´í„° í¬í•¨)
        documents = [
            "Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬ì´ ê°œë°œí•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
            "Python 3.12ëŠ” 2023ë…„ 10ì›”ì— ì¶œì‹œë˜ì—ˆìœ¼ë©° ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.",
            "íŒŒì´ì¬ì€ ë°ì´í„° ê³¼í•™ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.",
            "DjangoëŠ” Python ê¸°ë°˜ì˜ ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
            "ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ Pythonì´ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì´ìœ ëŠ” í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë•Œë¬¸ì…ë‹ˆë‹¤."
        ]
        
        metadatas = [
            {
                "source": "Wikipedia",
                "year": 2020,
                "topic": "history",
                "reliability": "high"
            },
            {
                "source": "Python.org",
                "year": 2023,
                "topic": "release",
                "reliability": "official"
            },
            {
                "source": "Survey2023",
                "year": 2023,
                "topic": "statistics",
                "reliability": "high"
            },
            {
                "source": "Django Docs",
                "year": 2022,
                "topic": "framework",
                "reliability": "official"
            },
            {
                "source": "ML Blog",
                "year": 2023,
                "topic": "machine_learning",
                "reliability": "medium"
            }
        ]
        
        # ë¬¸ì„œ ì¶”ê°€
        rag.add_documents(documents, metadatas)
        
        print("\n### 1. í•„í„°ë§ ì—†ëŠ” ì¼ë°˜ ê²€ìƒ‰")
        result1 = rag.query("Pythonì˜ ìµœì‹  ë²„ì „ì€?", top_k=3, use_metadata=True)
        print(f"ì§ˆë¬¸: Pythonì˜ ìµœì‹  ë²„ì „ì€?")
        print(f"ë‹µë³€: {result1['answer'][:200]}...")
        print(f"ì‚¬ìš©ëœ ì†ŒìŠ¤:")
        for source in result1['sources']:
            print(f"  - {source['metadata'].get('source', 'Unknown')}: {source['document'][:50]}...")
        
        print("\n### 2. ê³µì‹ ì†ŒìŠ¤ë§Œ í•„í„°ë§")
        result2 = rag.query(
            "Pythonì˜ ìµœì‹  ë²„ì „ì€?", 
            top_k=3,
            filter_metadata={"reliability": "official"}
        )
        print(f"ì§ˆë¬¸: Pythonì˜ ìµœì‹  ë²„ì „ì€? (ê³µì‹ ì†ŒìŠ¤ë§Œ)")
        print(f"ë‹µë³€: {result2['answer'][:200]}...")
        print(f"ì‚¬ìš©ëœ ì†ŒìŠ¤:")
        for source in result2['sources']:
            print(f"  - {source['metadata'].get('source', 'Unknown')} [{source['metadata'].get('reliability', '')}]")
        
        print("\n### 3. ìµœì‹  ì •ë³´ë§Œ í•„í„°ë§ (2023ë…„)")
        result3 = rag.query(
            "Pythonì˜ í˜„ì¬ ìƒí™©ì€?",
            top_k=3,
            filter_metadata={"year": 2023}
        )
        print(f"ì§ˆë¬¸: Pythonì˜ í˜„ì¬ ìƒí™©ì€? (2023ë…„ ì •ë³´ë§Œ)")
        print(f"ë‹µë³€: {result3['answer'][:200]}...")
        
        return rag

def explain_metadata_best_practices():
    """ë©”íƒ€ë°ì´í„° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤"""
    
    print("\n" + "="*60)
    print("ğŸ¯ RAG ì‹œìŠ¤í…œì—ì„œ ë©”íƒ€ë°ì´í„° í™œìš© ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤")
    print("="*60)
    
    practices = {
        "1. í•„ìˆ˜ ë©”íƒ€ë°ì´í„°": [
            "source: ì¶œì²˜ (ì‹ ë¢°ë„ í‰ê°€)",
            "timestamp: ìƒì„±/ìˆ˜ì • ì‹œê°„ (ìµœì‹ ì„± í‰ê°€)",
            "doc_type: ë¬¸ì„œ ìœ í˜• (ì²˜ë¦¬ ë°©ì‹ ê²°ì •)",
            "language: ì–¸ì–´ (ë‹¤êµ­ì–´ ì§€ì›)"
        ],
        
        "2. ë„ë©”ì¸ë³„ ë©”íƒ€ë°ì´í„°": [
            "í•™ìˆ : author, journal, doi, citations",
            "ë‰´ìŠ¤: publisher, category, region",
            "ì½”ë“œ: language, version, license",
            "ì œí’ˆ: price, category, brand, rating"
        ],
        
        "3. ì„±ëŠ¥ ìµœì í™” ë©”íƒ€ë°ì´í„°": [
            "chunk_id: ì²­í¬ ì‹ë³„ì",
            "parent_doc: ì›ë³¸ ë¬¸ì„œ ì°¸ì¡°",
            "embedding_version: ì„ë² ë”© ëª¨ë¸ ë²„ì „",
            "quality_score: í’ˆì§ˆ ì ìˆ˜"
        ],
        
        "4. ë©”íƒ€ë°ì´í„° í™œìš© ì‹œë‚˜ë¦¬ì˜¤": [
            "ì‹œê°„ í•„í„°ë§: ìµœì‹  ì •ë³´ë§Œ ê²€ìƒ‰",
            "ì‹ ë¢°ë„ í•„í„°ë§: ê³µì‹ ì†ŒìŠ¤ ìš°ì„ ",
            "ì–¸ì–´ í•„í„°ë§: íŠ¹ì • ì–¸ì–´ ë¬¸ì„œë§Œ",
            "ê¶Œí•œ ê´€ë¦¬: ì‚¬ìš©ìë³„ ì ‘ê·¼ ì œì–´"
        ]
    }
    
    for category, items in practices.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  â€¢ {item}")
    
    print("\n### ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸:")
    print("""
    1. ë©”íƒ€ë°ì´í„°ëŠ” ê²€ìƒ‰ ì •í™•ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤
    2. í•„í„°ë§ìœ¼ë¡œ ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë§Œ ì„ íƒ ê°€ëŠ¥
    3. ì¶œì²˜ ì¶”ì ê³¼ ë²„ì „ ê´€ë¦¬ê°€ ê°€ëŠ¥
    4. ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©
    5. ë‹µë³€ì˜ ì‹ ë¢°ë„ì™€ íˆ¬ëª…ì„± í–¥ìƒ
    """)

def compare_with_without_metadata():
    """ë©”íƒ€ë°ì´í„° ìˆìŒ/ì—†ìŒ ë¹„êµ"""
    
    print("\n" + "="*60)
    print("âš–ï¸ ë©”íƒ€ë°ì´í„° ìˆìŒ vs ì—†ìŒ ë¹„êµ")
    print("="*60)
    
    # ë©”íƒ€ë°ì´í„° ì—†ëŠ” RAG
    basic_rag = EnhancedRAG(collection_name="basic_rag")
    docs = [
        "AIëŠ” ë¯¸ë˜ ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "AIëŠ” ìœ„í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "AIëŠ” ì¼ìë¦¬ë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤."
    ]
    basic_rag.add_documents(docs, auto_metadata=False)
    
    # ë©”íƒ€ë°ì´í„° ìˆëŠ” RAG  
    enhanced_rag = EnhancedRAG(collection_name="enhanced_rag")
    docs_with_meta = [
        ("AIëŠ” ë¯¸ë˜ ê¸°ìˆ ì…ë‹ˆë‹¤.", {"source": "Tech Report 2024", "sentiment": "positive", "reliability": "high"}),
        ("AIëŠ” ìœ„í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", {"source": "Ethics Paper 2023", "sentiment": "negative", "reliability": "medium"}),
        ("AIëŠ” ì¼ìë¦¬ë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤.", {"source": "Economic Study 2023", "sentiment": "neutral", "reliability": "high"})
    ]
    
    for doc, meta in docs_with_meta:
        enhanced_rag.add_documents([doc], [meta])
    
    print("\n### ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ:")
    
    query = "AIì˜ ì˜í–¥ì€?"
    
    print(f"\nì§ˆë¬¸: {query}")
    print("\n1. ë©”íƒ€ë°ì´í„° ì—†ìŒ:")
    basic_result = basic_rag.query(query, use_metadata=False)
    print(f"   ë‹µë³€: {basic_result['answer'][:150]}...")
    print(f"   ì†ŒìŠ¤ êµ¬ë¶„: ë¶ˆê°€ëŠ¥")
    
    print("\n2. ë©”íƒ€ë°ì´í„° ìˆìŒ:")
    enhanced_result = enhanced_rag.query(query, use_metadata=True)
    print(f"   ë‹µë³€: {enhanced_result['answer'][:150]}...")
    print(f"   ì†ŒìŠ¤ ì •ë³´:")
    for source in enhanced_result['sources']:
        meta = source['metadata']
        print(f"     - {meta.get('source', 'Unknown')} [{meta.get('reliability', 'unknown')} reliability]")
    
    print("\n3. ì‹ ë¢°ë„ ë†’ì€ ì†ŒìŠ¤ë§Œ í•„í„°ë§:")
    filtered_result = enhanced_rag.query(
        query, 
        filter_metadata={"reliability": "high"}
    )
    print(f"   ë‹µë³€: {filtered_result['answer'][:150]}...")
    print(f"   ì‚¬ìš©ëœ ê³ ì‹ ë¢°ë„ ì†ŒìŠ¤: {len(filtered_result['sources'])}ê°œ")

if __name__ == "__main__":
    # ë©”íƒ€ë°ì´í„° ì¤‘ìš”ì„± ì‹œì—°
    rag_system = MetadataExamples.demonstrate_metadata_importance()
    
    # ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì„¤ëª…
    explain_metadata_best_practices()
    
    # ë¹„êµ ë¶„ì„
    compare_with_without_metadata()
    
    print("\n" + "="*60)
    print("âœ… ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!")
    print("="*60)